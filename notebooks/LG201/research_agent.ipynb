{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangGraph 201: Building a Deep Research Agent\n",
    "\n",
    "In this notebook, we'll build a multi-agent research system that can conduct comprehensive web research. We'll progressively build up the system in three parts:\n",
    "\n",
    "1. **Part 1**: Single researcher agent that performs web searches\n",
    "2. **Part 2**: Supervisor agent that coordinates multiple researchers\n",
    "3. **Part 3**: Complete workflow with user clarification and report generation\n",
    "\n",
    "This follows a common multi-agent pattern where a supervisor delegates work to specialized sub-agents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-work: Setup\n",
    "\n",
    "First, let's install dependencies and set up our environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI API key required for researcher\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    raise ValueError(\"OPENAI_API_KEY not found in environment variables\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import asyncio\n",
    "import operator\n",
    "from datetime import datetime\n",
    "from typing import Literal, Annotated\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    "    ToolMessage,\n",
    "    filter_messages,\n",
    "    get_buffer_string,\n",
    "    MessageLikeRepresentation\n",
    ")\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "from langgraph.types import Command, interrupt\n",
    "from typing_extensions import TypedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_today_str() -> str:\n",
    "    \"\"\"Get current date formatted for display.\"\"\"\n",
    "    now = datetime.now()\n",
    "    return f\"{now:%a} {now:%b} {now.day}, {now:%Y}\"\n",
    "\n",
    "def openai_websearch_called(response):\n",
    "    \"\"\"Detect if OpenAI's web search was used.\"\"\"\n",
    "    try:\n",
    "        tool_outputs = response.additional_kwargs.get(\"tool_outputs\")\n",
    "        if not tool_outputs:\n",
    "            return False\n",
    "        for tool_output in tool_outputs:\n",
    "            if tool_output.get(\"type\") == \"web_search_call\":\n",
    "                return True\n",
    "        return False\n",
    "    except (AttributeError, TypeError):\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuration\n",
    "\n",
    "Let's define our hardcoded configuration. In a production system, these would be configurable, but for this educational example we'll keep them simple and visible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Configuration set: openai:gpt-4.1\n"
     ]
    }
   ],
   "source": [
    "# Model configuration\n",
    "RESEARCH_MODEL = \"openai:gpt-4.1\" # Hard requirement for this notebook\n",
    "MAX_OUTPUT_TOKENS = 10000\n",
    "\n",
    "# Research limits\n",
    "MAX_RESEARCHER_ITERATIONS = 3  # How many times supervisor can delegate\n",
    "MAX_REACT_TOOL_CALLS = 10      # Max tool calls per researcher\n",
    "MAX_CONCURRENT_RESEARCH_UNITS = 5  # Max parallel researchers\n",
    "MAX_STRUCTURED_OUTPUT_RETRIES = 3\n",
    "\n",
    "# Initialize model\n",
    "def get_model():\n",
    "    return init_chat_model(\n",
    "        model=RESEARCH_MODEL,\n",
    "        max_tokens=MAX_OUTPUT_TOKENS,\n",
    "        api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "        use_responses_api=True\n",
    "    )\n",
    "\n",
    "print(f\"✓ Configuration set: {RESEARCH_MODEL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Building a Single Researcher Agent\n",
    "\n",
    "We'll start by building a single researcher agent that can:\n",
    "1. Receive a research topic\n",
    "2. Use web search to gather information\n",
    "3. Compress the findings into a summary\n",
    "\n",
    "This agent uses a ReAct (Reasoning and Acting) pattern with web search capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Define State\n",
    "\n",
    "How does information flow through the steps?  \n",
    "\n",
    "State is the first LangGraph concept we'll cover. **State can be thought of as the memory of the agent - its a shared data structure that’s passed on between the nodes of your graph**, representing the current snapshot of your application. \n",
    "\n",
    "For our Researcher, we'll define 3 fields to track: the conversation history, the topic, and how many API calls it has made. \n",
    "\n",
    "We can also define specific output State to indicate what we expect the researcher to return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResearcherState(TypedDict):\n",
    "    \"\"\"State for a single researcher agent.\"\"\"\n",
    "    researcher_messages: Annotated[list[MessageLikeRepresentation], operator.add]\n",
    "    research_topic: str        # What to research\n",
    "    tool_call_iterations: int  # How many tool calls made\n",
    "\n",
    "class ResearcherOutputState(TypedDict):\n",
    "    \"\"\"Output from researcher - just the compressed findings.\"\"\"\n",
    "    researcher_messages: Annotated[list[MessageLikeRepresentation], operator.add]\n",
    "    compressed_research: str   # Summary of findings\n",
    "    raw_notes: list           # Raw notes for later use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Define Tools\n",
    "\n",
    "Let's define a list of **tools** our agent will have access to. Tools are functionts that can act as extension of the LLM's capabilities. \n",
    "\n",
    "We'll define some no-op tools that will allow our researcher to reflect and indicate when research is complete.\n",
    "\n",
    "Finally, to actually conduct research, our agent needs access to web search. We'll use OpenAI's native web search capability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(description=\"Signal that research is complete\")\n",
    "def ResearchComplete() -> str:\n",
    "    \"\"\"Call this when you have gathered enough information to answer the research question.\"\"\"\n",
    "    return \"Research marked as complete\"\n",
    "\n",
    "@tool(description=\"Strategic reflection tool for research planning\")\n",
    "def think_tool(reflection: str) -> str:\n",
    "    \"\"\"Use this tool after each search to analyze results and plan next steps.\n",
    "    \n",
    "    Args:\n",
    "        reflection: Detailed reflection on research progress and next steps\n",
    "    \"\"\"\n",
    "    return f\"Reflection recorded: {reflection}\"\n",
    "\n",
    "async def get_all_tools():\n",
    "    \"\"\"Get all available research tools.\"\"\"\n",
    "    tools = [ResearchComplete, think_tool]\n",
    "    # OpenAI's native web search - bind it so model knows it's available, but we don't execute it\n",
    "    tools.append({\"type\": \"web_search_preview\"})\n",
    "    return tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Define Nodes\n",
    "\n",
    "Now that we have a list of tools, we are ready to build nodes that interact with them. \n",
    "\n",
    "Nodes are just python (or JS/TS!) functions. Nodes take in your graph's State as input, execute some logic, and return a new State. \n",
    "\n",
    "Here, we're just going to set up 2 nodes for our ReAct agent:\n",
    "1. **researcher**: Reasoning node that decides which function to invoke \n",
    "2. **researcher_tools**: Node that contains all the available tools and executes the function\n",
    "\n",
    "We'll start with the reasoning node, which will utilize a prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "research_system_prompt = \"\"\"You are a research assistant conducting research on the user's input topic. For context, today's date is {date}.\n",
    "\n",
    "<Task>\n",
    "Your job is to use tools to gather information about the user's input topic.\n",
    "You can use any of the tools provided to you to find resources that can help answer the research question.\n",
    "</Task>\n",
    "\n",
    "<Available Tools>\n",
    "You have access to:\n",
    "1. **Web search**: For conducting web searches to gather information\n",
    "2. **think_tool**: For reflection and strategic planning during research\n",
    "\n",
    "**CRITICAL: Use think_tool after each search to reflect on results and plan next steps.**\n",
    "</Available Tools>\n",
    "\n",
    "<Instructions>\n",
    "Think like a human researcher with limited time:\n",
    "\n",
    "1. **Read the question carefully** - What specific information does the user need?\n",
    "2. **Start with broader searches** - Use broad, comprehensive queries first\n",
    "3. **After each search, pause and assess** - Do I have enough to answer? What's still missing?\n",
    "4. **Execute narrower searches as you gather information** - Fill in the gaps\n",
    "5. **Stop when you can answer confidently** - Don't keep searching for perfection\n",
    "</Instructions>\n",
    "\n",
    "<Hard Limits>\n",
    "**Tool Call Budgets**:\n",
    "- **Simple queries**: Use 2-3 search tool calls maximum\n",
    "- **Complex queries**: Use up to 5 search tool calls maximum\n",
    "- **Always stop**: After 5 search tool calls if you cannot find the right sources\n",
    "\n",
    "**Stop Immediately When**:\n",
    "- You can answer the user's question comprehensively\n",
    "- You have 3+ relevant examples/sources for the question\n",
    "- Your last 2 searches returned similar information\n",
    "</Hard Limits>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can use this prompt in our reasoning node. We'll give our tools to our configured LLM model, and invoke it with our prompt to see what tools it wants to call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def researcher(state: ResearcherState, config):\n",
    "    \"\"\"Main researcher node that conducts research.\"\"\"\n",
    "    researcher_messages = state.get(\"researcher_messages\", [])\n",
    "    \n",
    "    # Get research tools\n",
    "    tools = await get_all_tools()    \n",
    "    # Prepare system prompt\n",
    "    researcher_prompt = research_system_prompt.format(date=get_today_str())\n",
    "    \n",
    "    # Configure model with tools\n",
    "    research_model = (\n",
    "        get_model()\n",
    "        .bind_tools(tools)\n",
    "        .with_retry(stop_after_attempt=MAX_STRUCTURED_OUTPUT_RETRIES)\n",
    "    )\n",
    "    \n",
    "    # Generate researcher response\n",
    "    messages = [SystemMessage(content=researcher_prompt)] + researcher_messages\n",
    "    response = await research_model.ainvoke(messages)\n",
    "    \n",
    "    # Update state\n",
    "    return {\n",
    "        \"researcher_messages\": [response],\n",
    "        \"tool_call_iterations\": state.get(\"tool_call_iterations\", 0) + 1\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can define the tools node to actually execute the tool calls that the LLM wants to make. We'll also introduce the concept of a Command, which is a special object that allows you to not only update the State, but also determine which node to execute next.\n",
    "\n",
    "Commands serve as an alternative to edges, which we'll cover next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def execute_tool_safely(tool, args):\n",
    "    \"\"\"Safely execute a tool with error handling.\"\"\"\n",
    "    try:\n",
    "        return await tool.ainvoke(args)\n",
    "    except Exception as e:\n",
    "        return f\"Error executing tool: {str(e)}\"\n",
    "\n",
    "async def researcher_tools(state: ResearcherState, config) -> Command[Literal[\"researcher\", \"compress_research\"]]:\n",
    "    \"\"\"Execute tools called by the researcher.\"\"\"\n",
    "    researcher_messages = state.get(\"researcher_messages\", [])\n",
    "    most_recent_message = researcher_messages[-1]\n",
    "    \n",
    "    # Check if there are tool calls or native search\n",
    "    has_tool_calls = bool(most_recent_message.tool_calls)\n",
    "    has_native_search = openai_websearch_called(most_recent_message)\n",
    "    \n",
    "    if not has_tool_calls and not has_native_search:\n",
    "        return Command(goto=\"compress_research\")\n",
    "    \n",
    "    # Execute tool calls\n",
    "    tools = await get_all_tools()\n",
    "    tools_by_name = {\n",
    "        tool.name if hasattr(tool, \"name\") else tool.get(\"name\", \"web_search\"): tool\n",
    "        for tool in tools\n",
    "    }\n",
    "    \n",
    "    tool_calls = most_recent_message.tool_calls\n",
    "    tool_execution_tasks = [\n",
    "        execute_tool_safely(tools_by_name[tc[\"name\"]], tc[\"args\"])\n",
    "        for tc in tool_calls\n",
    "    ]\n",
    "    observations = await asyncio.gather(*tool_execution_tasks)\n",
    "    \n",
    "    # Create tool messages\n",
    "    tool_outputs = [\n",
    "        ToolMessage(\n",
    "            content=observation,\n",
    "            name=tc[\"name\"],\n",
    "            tool_call_id=tc[\"id\"]\n",
    "        )\n",
    "        for observation, tc in zip(observations, tool_calls)\n",
    "    ]\n",
    "    \n",
    "    # Check exit conditions\n",
    "    exceeded_iterations = state.get(\"tool_call_iterations\", 0) >= MAX_REACT_TOOL_CALLS\n",
    "    research_complete = any(\n",
    "        tc[\"name\"] == \"ResearchComplete\"\n",
    "        for tc in most_recent_message.tool_calls\n",
    "    )\n",
    "    \n",
    "    if exceeded_iterations or research_complete:\n",
    "        return Command(\n",
    "            goto=\"compress_research\",\n",
    "            update={\"researcher_messages\": tool_outputs}\n",
    "        )\n",
    "    \n",
    "    # Continue research loop\n",
    "    return Command(\n",
    "        goto=\"researcher\",\n",
    "        update={\"researcher_messages\": tool_outputs}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "compress_research_system_prompt = \"\"\"You are a research assistant that has conducted research on a topic. Your job is to clean up the findings.\n",
    "\n",
    "<Task>\n",
    "Clean up information gathered from tool calls and web searches. All relevant information should be repeated verbatim.\n",
    "The purpose is just to remove obviously irrelevant or duplicative information.\n",
    "</Task>\n",
    "\n",
    "<Guidelines>\n",
    "1. Your output should be fully comprehensive and include ALL information and sources gathered\n",
    "2. Include inline citations [1], [2], etc. for each source\n",
    "3. Include a \"Sources\" section at the end listing all sources with citations\n",
    "4. Make sure to include ALL sources - a later LLM will merge this with other reports\n",
    "</Guidelines>\n",
    "\"\"\"\n",
    "\n",
    "async def compress_research(state: ResearcherState, config):\n",
    "    \"\"\"Compress and synthesize research findings.\"\"\"\n",
    "    researcher_messages = state.get(\"researcher_messages\", [])\n",
    "    \n",
    "    # Add compression instruction\n",
    "    researcher_messages.append(\n",
    "        HumanMessage(content=\"Please clean up these findings. DO NOT summarize - preserve all relevant information verbatim.\")\n",
    "    )\n",
    "    \n",
    "    # Create compression prompt\n",
    "    compression_prompt = compress_research_system_prompt\n",
    "    messages = [SystemMessage(content=compression_prompt)] + researcher_messages\n",
    "    \n",
    "    # Execute compression\n",
    "    response = await get_model().ainvoke(messages)\n",
    "    \n",
    "    # Extract raw notes\n",
    "    raw_notes_content = \"\\n\".join([\n",
    "        str(message.content)\n",
    "        for message in filter_messages(researcher_messages, include_types=[\"tool\", \"ai\"])\n",
    "    ])\n",
    "    \n",
    "    return {\n",
    "        \"compressed_research\": str(response.content),\n",
    "        \"raw_notes\": [raw_notes_content]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Define Edges and Build Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Edges are connections between nodes. They define the flow of the graph.**\n",
    "* **Normal edges** are deterministic and always go from one node to its defined target\n",
    "* **Conditional edges** are used to dynamically route between nodes, implemented as functions that return the next node to visit based upon some logic. \n",
    "\n",
    "In this case, our conditional routing is handled by Commands, so we can link together the nodes of our graph using normal edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x108901fd0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build researcher graph\n",
    "researcher_builder = StateGraph(\n",
    "    ResearcherState,\n",
    "    output_schema=ResearcherOutputState\n",
    ")\n",
    "\n",
    "# Add nodes\n",
    "researcher_builder.add_node(\"researcher\", researcher)\n",
    "researcher_builder.add_node(\"researcher_tools\", researcher_tools)\n",
    "researcher_builder.add_node(\"compress_research\", compress_research)\n",
    "\n",
    "# Add edges\n",
    "researcher_builder.add_edge(START, \"researcher\")\n",
    "researcher_builder.add_edge(\"researcher\", \"researcher_tools\")\n",
    "# researcher_tools uses Command to route to either researcher or compress_research\n",
    "researcher_builder.add_edge(\"compress_research\", END)\n",
    "\n",
    "# Compile\n",
    "researcher_graph = researcher_builder.compile()\n",
    "researcher_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Running the Single Researcher\n",
    "\n",
    "Let's test our researcher with a simple query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RESEARCHER MESSAGE HISTORY:\n",
      "============================================================\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What are the best practices for prompt engineering with LLMs?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'id': 'ws_04533662bd75c49400695df697f9ac8194b637cf883272b0e4', 'action': {'query': 'best practices for prompt engineering with LLMs 2025', 'type': 'search'}, 'status': 'completed', 'type': 'web_search_call'}, {'type': 'text', 'text': 'Prompt engineering is the practice of crafting inputs to guide large language models (LLMs) toward producing desired outputs. Effective prompt engineering enhances the accuracy, relevance, and reliability of AI-generated content. Here are some best practices:\\n\\n1. **Clarity and Specificity**: Clearly define the task and provide specific instructions to reduce ambiguity. For example, instead of \"Write a summary,\" specify \"Summarize the key themes of post-colonial literature in 300 words for a high school curriculum.\" ([containsai.com](https://containsai.com/evolution-best-practices-prompt-engineering-2025-md/?utm_source=openai))\\n\\n2. **Contextual Framing and Constraints**: Provide relevant context and set constraints to guide the model\\'s responses. For instance, when requesting code generation, include architectural details and compliance requirements to ensure the output meets specific needs. ([containsai.com](https://containsai.com/evolution-best-practices-prompt-engineering-2025-md/?utm_source=openai))\\n\\n3. **Iterative Refinement and Feedback Loops**: Treat prompt engineering as an iterative process. Analyze the model\\'s outputs, identify shortcomings, and refine prompts accordingly to improve results over time. ([promptden.com](https://promptden.com/blog/8-advanced-prompt-engineering-tips-for-2025?utm_source=openai))\\n\\n4. **Use of Advanced Techniques**:\\n   - **Chain-of-Thought Prompting**: Encourage the model to break down complex problems into smaller steps, enhancing reasoning and accuracy. ([vibemakers.ai](https://vibemakers.ai/library/prompt-engineering-tips-boost-ai-effectiveness-2025?utm_source=openai))\\n   - **Meta Prompting**: Utilize LLMs to generate and refine prompts for themselves or other models, automating the creation of effective prompts. ([androidcentral.com](https://www.androidcentral.com/apps-software/ai/a-google-deepmind-engineer-just-shared-the-secret-to-generating-videos-with-veo-in-gemini?utm_source=openai))\\n   - **Tree-of-Thought Prompting**: Allow the model to explore multiple solution paths simultaneously, fostering creative problem-solving. ([adaline.ai](https://www.adaline.ai/blog/how-to-write-a-prompt-in-2025?utm_source=openai))\\n\\n5. **Security Considerations**: Be aware of vulnerabilities like prompt injection attacks. Implement safeguards such as input/output validation and adhere to the principle of least privilege to mitigate risks. ([techradar.com](https://www.techradar.com/pro/security/prompt-injection-attacks-might-never-be-properly-mitigated-uk-ncsc-warns?utm_source=openai))\\n\\n6. **Utilization of Prompt Management Tools**: Employ tools like LangChain for structured prompt workflows, PromptLayer for version control, and Rebuff for detecting prompt injection attempts to enhance prompt engineering practices. ([refontelearning.com](https://www.refontelearning.com/blog/whats-powering-prompt-engineering-trends-2025?utm_source=openai))\\n\\nBy adhering to these best practices, you can effectively guide LLMs to produce outputs that are accurate, relevant, and aligned with your objectives. ', 'annotations': [{'end_index': 634, 'start_index': 521, 'title': 'The Evolution and Best Practices of Prompt Engineering in 2025 — ContainsAI', 'type': 'url_citation', 'url': 'https://containsai.com/evolution-best-practices-prompt-engineering-2025-md/?utm_source=openai'}, {'end_index': 1017, 'start_index': 904, 'title': 'The Evolution and Best Practices of Prompt Engineering in 2025 — ContainsAI', 'type': 'url_citation', 'url': 'https://containsai.com/evolution-best-practices-prompt-engineering-2025-md/?utm_source=openai'}, {'end_index': 1337, 'start_index': 1230, 'title': '8 Advanced Prompt Engineering Tips For 2025 • PromptDen', 'type': 'url_citation', 'url': 'https://promptden.com/blog/8-advanced-prompt-engineering-tips-for-2025?utm_source=openai'}, {'end_index': 1634, 'start_index': 1516, 'title': 'Prompt Engineering Tips: Boost AI Effectiveness in 2025 | VibeMakers Library', 'type': 'url_citation', 'url': 'https://vibemakers.ai/library/prompt-engineering-tips-boost-ai-effectiveness-2025?utm_source=openai'}, {'end_index': 1961, 'start_index': 1782, 'title': 'A Google DeepMind engineer just shared the secret to making the perfect Gemini prompt', 'type': 'url_citation', 'url': 'https://www.androidcentral.com/apps-software/ai/a-google-deepmind-engineer-just-shared-the-secret-to-generating-videos-with-veo-in-gemini?utm_source=openai'}, {'end_index': 2192, 'start_index': 2101, 'title': 'How to Write a Prompt in 2025 | Adaline', 'type': 'url_citation', 'url': 'https://www.adaline.ai/blog/how-to-write-a-prompt-in-2025?utm_source=openai'}, {'end_index': 2552, 'start_index': 2404, 'title': \"Prompt injection attacks might 'never be properly mitigated' UK NCSC warns\", 'type': 'url_citation', 'url': 'https://www.techradar.com/pro/security/prompt-injection-attacks-might-never-be-properly-mitigated-uk-ncsc-warns?utm_source=openai'}, {'end_index': 2912, 'start_index': 2787, 'title': 'Refonte Learning : Tools to Watch: What’s Powering Prompt Engineering Trends 2025', 'type': 'url_citation', 'url': 'https://www.refontelearning.com/blog/whats-powering-prompt-engineering-trends-2025?utm_source=openai'}], 'id': 'msg_04533662bd75c49400695df69a1b788194887e89bd02cfa91c'}, {'arguments': '{\"reflection\":\"The initial search has provided a comprehensive set of best practices from multiple recent and reputable sources, covering instructions clarity, iterative refinement, advanced prompting techniques, security, and the use of management tools. Next, assess whether there are any major gaps—such as practical examples or user-case specificity—or if current information already addresses the core user request about best practices for prompt engineering with LLMs.\"}', 'call_id': 'call_bWAjFRpgwkbhLws6DMlmNB7s', 'name': 'think_tool', 'type': 'function_call', 'id': 'fc_04533662bd75c49400695df6a5a4248194b55f9129c6c0e788', 'status': 'completed'}]\n",
      "Tool Calls:\n",
      "  think_tool (call_bWAjFRpgwkbhLws6DMlmNB7s)\n",
      " Call ID: call_bWAjFRpgwkbhLws6DMlmNB7s\n",
      "  Args:\n",
      "    reflection: The initial search has provided a comprehensive set of best practices from multiple recent and reputable sources, covering instructions clarity, iterative refinement, advanced prompting techniques, security, and the use of management tools. Next, assess whether there are any major gaps—such as practical examples or user-case specificity—or if current information already addresses the core user request about best practices for prompt engineering with LLMs.\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: think_tool\n",
      "\n",
      "Reflection recorded: The initial search has provided a comprehensive set of best practices from multiple recent and reputable sources, covering instructions clarity, iterative refinement, advanced prompting techniques, security, and the use of management tools. Next, assess whether there are any major gaps—such as practical examples or user-case specificity—or if current information already addresses the core user request about best practices for prompt engineering with LLMs.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'type': 'text', 'text': 'Based on the most up-to-date sources and best practices, here is a summary of prompt engineering recommendations for large language models (LLMs):\\n\\n1. Be clear and specific: Provide explicit instructions and directly state what you want the LLM to do.\\n   - Example: Prefer \"Generate a summary of news articles about renewable energy from the last year\" to \"Summarize recent events.\"\\n\\n2. Provide context and constraints: Add context to steer the model, and set boundaries or formats for the response.\\n   - Example: \"Answer in bullet points and keep each point under 20 words.\"\\n\\n3. Use iterative refinement: Treat prompt engineering as a cycle—analyze outputs, adjust the prompt, and test again to get closer to your desired result.\\n\\n4. Apply advanced prompting strategies: \\n   - Chain-of-Thought: Ask the model to reason step by step by adding \"Let\\'s think through this step by step.\"\\n   - Meta-prompting: Use the LLM to create or improve prompts for itself or for other LLMs.\\n   - Tree-of-Thought: Encourage exploration of multiple solutions by prompting, \"List several possible solutions before choosing the best.\"\\n\\n5. Consider security issues: Guard against prompt injection by sanitizing inputs/outputs, and follow the principle of least privilege when giving context or access.\\n\\n6. Use tooling: Adopt prompt management tools (like LangChain, PromptLayer, or Rebuff) for systematic prompt testing, tracking, and security.\\n\\nThese best practices help ensure that LLM outputs are accurate, relevant, and safe. If you want case studies, domain-specific tips, or further resources, let me know!', 'annotations': [], 'id': 'msg_04533662bd75c49400695df6a820e48194bdc7e5ed9d0a3206'}]\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Please clean up these findings. DO NOT summarize - preserve all relevant information verbatim.\n",
      "\n",
      "============================================================\n",
      "RESEARCH FINDINGS:\n",
      "============================================================\n",
      "[{'type': 'text', 'text': 'Prompt engineering is the practice of crafting inputs to guide large language models (LLMs) toward producing desired outputs. Effective prompt engineering enhances the accuracy, relevance, and reliability of AI-generated content. Here are some best practices:\\n\\n1. **Clarity and Specificity**: Clearly define the task and provide specific instructions to reduce ambiguity. For example, instead of \"Write a summary,\" specify \"Summarize the key themes of post-colonial literature in 300 words for a high school curriculum.\" [1]\\n\\n2. **Contextual Framing and Constraints**: Provide relevant context and set constraints to guide the model\\'s responses. For instance, when requesting code generation, include architectural details and compliance requirements to ensure the output meets specific needs. [1]\\n\\n3. **Iterative Refinement and Feedback Loops**: Treat prompt engineering as an iterative process. Analyze the model\\'s outputs, identify shortcomings, and refine prompts accordingly to improve results over time. [2]\\n\\n4. **Use of Advanced Techniques**:\\n   - **Chain-of-Thought Prompting**: Encourage the model to break down complex problems into smaller steps, enhancing reasoning and accuracy. [3]\\n   - **Meta Prompting**: Utilize LLMs to generate and refine prompts for themselves or other models, automating the creation of effective prompts. [4]\\n   - **Tree-of-Thought Prompting**: Allow the model to explore multiple solution paths simultaneously, fostering creative problem-solving. [5]\\n\\n5. **Security Considerations**: Be aware of vulnerabilities like prompt injection attacks. Implement safeguards such as input/output validation and adhere to the principle of least privilege to mitigate risks. [6]\\n\\n6. **Utilization of Prompt Management Tools**: Employ tools like LangChain for structured prompt workflows, PromptLayer for version control, and Rebuff for detecting prompt injection attempts to enhance prompt engineering practices. [7]\\n\\nBy adhering to these best practices, you can effectively guide LLMs to produce outputs that are accurate, relevant, and aligned with your objectives.\\n\\nSources:\\n1. https://containsai.com/evolution-best-practices-prompt-engineering-2025-md/?utm_source=openai\\n2. https://promptden.com/blog/8-advanced-prompt-engineering-tips-for-2025?utm_source=openai\\n3. https://vibemakers.ai/library/prompt-engineering-tips-boost-ai-effectiveness-2025?utm_source=openai\\n4. https://www.androidcentral.com/apps-software/ai/a-google-deepmind-engineer-just-shared-the-secret-to-generating-videos-with-veo-in-gemini?utm_source=openai\\n5. https://www.adaline.ai/blog/how-to-write-a-prompt-in-2025?utm_source=openai\\n6. https://www.techradar.com/pro/security/prompt-injection-attacks-might-never-be-properly-mitigated-uk-ncsc-warns?utm_source=openai\\n7. https://www.refontelearning.com/blog/whats-powering-prompt-engineering-trends-2025?utm_source=openai', 'annotations': [], 'id': 'msg_04533662bd75c49400695df6b08c6881948a6518023d96819b'}]\n"
     ]
    }
   ],
   "source": [
    "# Test the researcher\n",
    "test_query = \"What are the best practices for prompt engineering with LLMs?\"\n",
    "\n",
    "initial_state = {\n",
    "    \"researcher_messages\": [HumanMessage(content=test_query)],\n",
    "    \"research_topic\": test_query,\n",
    "    \"tool_call_iterations\": 0\n",
    "}\n",
    "\n",
    "result = await researcher_graph.ainvoke(initial_state)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"RESEARCHER MESSAGE HISTORY:\")\n",
    "print(\"=\"*60)\n",
    "for message in result[\"researcher_messages\"]:\n",
    "    message.pretty_print()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RESEARCH FINDINGS:\")\n",
    "print(\"=\"*60)\n",
    "print(result[\"compressed_research\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Building the Supervisor Agent\n",
    "\n",
    "Now we'll build a supervisor agent that can:\n",
    "1. Break down a research question into multiple sub-topics\n",
    "2. Delegate research to multiple researcher agents in parallel\n",
    "3. Collect and organize all the findings\n",
    "\n",
    "This demonstrates the power of multi-agent systems!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Define Supervisor State"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define separate state for our Supervisor. This allows it to keep track different items than the Researcher, preventing it from getting distracted by noise. \n",
    "\n",
    "We also define a customer reducer for handling specific state keys. By default state updates overwrite existing values - we've defined a custom reducer to allow for concatenation alongside overwrite behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def override_reducer(current_value, new_value):\n",
    "    \"\"\"Reducer function that allows overriding values in state.\"\"\"\n",
    "    if isinstance(new_value, dict) and new_value.get(\"type\") == \"override\":\n",
    "        return new_value.get(\"value\", new_value)\n",
    "    else:\n",
    "        return operator.add(current_value, new_value)\n",
    "        \n",
    "class SupervisorState(TypedDict):\n",
    "    \"\"\"State for the supervisor agent.\"\"\"\n",
    "    supervisor_messages: Annotated[list[MessageLikeRepresentation], override_reducer]\n",
    "    research_brief: str\n",
    "    notes: Annotated[list[str], override_reducer] = []\n",
    "    research_iterations: int = 0\n",
    "    raw_notes: Annotated[list[str], override_reducer] = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Define Supervisor Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In multi-agent systems, the most common way to coordinate subagents today is to call them as tools. This allows subagents to isolate their context from the supervisor's orchestration, allowing specialization and focus.\n",
    "\n",
    "This is as simple as invoking our researcher subagent within a tool, and giving that tool to our supervisor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(description=\"Delegate a research task to a specialized researcher\")\n",
    "async def ConductResearch(research_topic: str) -> dict:\n",
    "    \"\"\"Delegate a specific research topic to a researcher agent.\n",
    "    \n",
    "    Args:\n",
    "        research_topic: Clear, specific research question for the sub-agent\n",
    "    \"\"\"\n",
    "    # Actually invoke the researcher graph\n",
    "    result = await researcher_graph.ainvoke({\n",
    "        \"researcher_messages\": [HumanMessage(content=research_topic)],\n",
    "        \"research_topic\": research_topic,\n",
    "        \"tool_call_iterations\": 0\n",
    "    })\n",
    "    \n",
    "    # Return dictionary directly with both compressed research and raw notes\n",
    "    return {\n",
    "        \"compressed_research\": result.get(\"compressed_research\", \"Error in research\"),\n",
    "        \"raw_notes\": result.get(\"raw_notes\", [])\n",
    "    }\n",
    "\n",
    "@tool(description=\"Signal that all research is complete\")\n",
    "def ResearchComplete() -> str:\n",
    "    \"\"\"Call this when you have gathered all necessary information.\"\"\"\n",
    "    return \"Research marked as complete\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Define Supervisor Nodes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_researcher_prompt = \"\"\"You are a research supervisor. Your job is to conduct research by calling the \"ConductResearch\" tool.\n",
    "\n",
    "<Task>\n",
    "Call the \"ConductResearch\" tool to delegate research. When you're satisfied with findings, call \"ResearchComplete\".\n",
    "</Task>\n",
    "\n",
    "<Available Tools>\n",
    "1. **ConductResearch**: Delegate research tasks to specialized sub-agents\n",
    "2. **ResearchComplete**: Indicate that research is complete\n",
    "3. **think_tool**: For reflection and strategic planning\n",
    "\n",
    "**CRITICAL: Use think_tool before calling ConductResearch to plan, and after to assess progress.**\n",
    "</Available Tools>\n",
    "\n",
    "<Instructions>\n",
    "Think like a research manager:\n",
    "\n",
    "1. **Read the question carefully** - What specific information is needed?\n",
    "2. **Decide how to delegate** - Can multiple independent angles be explored simultaneously?\n",
    "3. **After each ConductResearch call, assess** - Do I have enough? What's missing?\n",
    "</Instructions>\n",
    "\n",
    "<Hard Limits>\n",
    "- **Limit tool calls** - Stop after {max_researcher_iterations} tool calls if you cannot find the right sources\n",
    "- **Maximum {max_concurrent_research_units} parallel agents per iteration**\n",
    "</Hard Limits>\n",
    "\n",
    "<Scaling Rules>\n",
    "**Simple queries** - Use a single sub-agent\n",
    "**Comparisons** - Use a sub-agent for each element being compared\n",
    "**Important**: Provide complete standalone instructions when calling ConductResearch\n",
    "</Scaling Rules>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def supervisor(state: SupervisorState, config):\n",
    "    \"\"\"Supervisor agent that delegates research.\"\"\"\n",
    "    lead_researcher_tools = [ConductResearch, ResearchComplete, think_tool]\n",
    "    \n",
    "    research_model = (\n",
    "        get_model()\n",
    "        .bind_tools(lead_researcher_tools)\n",
    "        .with_retry(stop_after_attempt=MAX_STRUCTURED_OUTPUT_RETRIES)\n",
    "    )\n",
    "    \n",
    "    supervisor_messages = state.get(\"supervisor_messages\", [])\n",
    "    response = await research_model.ainvoke(supervisor_messages)\n",
    "    \n",
    "    return {\n",
    "        \"supervisor_messages\": [response],\n",
    "        \"research_iterations\": state.get(\"research_iterations\", 0) + 1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tool_content(messages):\n",
    "    \"\"\"Extract notes from tool call messages.\"\"\"\n",
    "    return [tool_msg.content for tool_msg in filter_messages(messages, include_types=\"tool\")]\n",
    "\n",
    "async def supervisor_tools(state: SupervisorState, config) -> Command[Literal[\"supervisor\", \"__end__\"]]:\n",
    "    \"\"\"Execute tools called by the supervisor.\"\"\"\n",
    "    supervisor_messages = state.get(\"supervisor_messages\", [])\n",
    "    research_iterations = state.get(\"research_iterations\", 0)\n",
    "    most_recent_message = supervisor_messages[-1]\n",
    "    \n",
    "    # Check exit conditions\n",
    "    exceeded_iterations = research_iterations > MAX_RESEARCHER_ITERATIONS\n",
    "    no_tool_calls = not most_recent_message.tool_calls\n",
    "    research_complete = any(\n",
    "        tc[\"name\"] == \"ResearchComplete\"\n",
    "        for tc in most_recent_message.tool_calls\n",
    "    )\n",
    "    \n",
    "    if exceeded_iterations or no_tool_calls or research_complete:\n",
    "        return Command(\n",
    "            goto=END,\n",
    "            update={\n",
    "                \"notes\": extract_tool_content(supervisor_messages),\n",
    "                \"research_brief\": state.get(\"research_brief\", \"\")\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    # Process tool calls\n",
    "    all_tool_messages = []\n",
    "    update_payload = {\"supervisor_messages\": []}\n",
    "    \n",
    "    # Handle think_tool\n",
    "    for tc in most_recent_message.tool_calls:\n",
    "        if tc[\"name\"] == \"think_tool\":\n",
    "            all_tool_messages.append(ToolMessage(\n",
    "                content=f\"Reflection recorded: {tc['args']['reflection']}\",\n",
    "                name=\"think_tool\",\n",
    "                tool_call_id=tc[\"id\"]\n",
    "            ))\n",
    "    \n",
    "    # Handle ConductResearch - now executes the actual tool\n",
    "    conduct_research_calls = [\n",
    "        tc for tc in most_recent_message.tool_calls\n",
    "        if tc[\"name\"] == \"ConductResearch\"\n",
    "    ]\n",
    "    \n",
    "    if conduct_research_calls:\n",
    "        try:\n",
    "            allowed_calls = conduct_research_calls[:MAX_CONCURRENT_RESEARCH_UNITS]\n",
    "            overflow_calls = conduct_research_calls[MAX_CONCURRENT_RESEARCH_UNITS:]\n",
    "            \n",
    "            # Execute research tasks in parallel by invoking the tool\n",
    "            research_tasks = [\n",
    "                ConductResearch.ainvoke(tc[\"args\"])\n",
    "                for tc in allowed_calls\n",
    "            ]\n",
    "            \n",
    "            # Get results directly as dictionaries\n",
    "            tool_results = await asyncio.gather(*research_tasks)\n",
    "            \n",
    "            # Create tool messages with results\n",
    "            for observation_dict, tc in zip(tool_results, allowed_calls):\n",
    "                all_tool_messages.append(ToolMessage(\n",
    "                    content=observation_dict.get(\"compressed_research\", \"Error in research\"),\n",
    "                    name=tc[\"name\"],\n",
    "                    tool_call_id=tc[\"id\"]\n",
    "                ))\n",
    "            \n",
    "            # Handle overflow\n",
    "            for overflow_call in overflow_calls:\n",
    "                all_tool_messages.append(ToolMessage(\n",
    "                    content=f\"Error: Exceeded max concurrent units ({MAX_CONCURRENT_RESEARCH_UNITS})\",\n",
    "                    name=\"ConductResearch\",\n",
    "                    tool_call_id=overflow_call[\"id\"]\n",
    "                ))\n",
    "            \n",
    "            # Aggregate raw notes\n",
    "            raw_notes_concat = \"\\n\".join([\n",
    "                \"\\n\".join(obs.get(\"raw_notes\", []))\n",
    "                for obs in tool_results\n",
    "            ])\n",
    "            \n",
    "            if raw_notes_concat:\n",
    "                update_payload[\"raw_notes\"] = [raw_notes_concat]\n",
    "        \n",
    "        except Exception as e:\n",
    "            return Command(\n",
    "                goto=END,\n",
    "                update={\n",
    "                    \"notes\": extract_tool_content(supervisor_messages),\n",
    "                    \"research_brief\": state.get(\"research_brief\", \"\")\n",
    "                }\n",
    "            )\n",
    "    \n",
    "    update_payload[\"supervisor_messages\"] = all_tool_messages\n",
    "    return Command(goto=\"supervisor\", update=update_payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Build Supervisor Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build supervisor graph\n",
    "supervisor_builder = StateGraph(SupervisorState)\n",
    "supervisor_builder.add_node(\"supervisor\", supervisor)\n",
    "supervisor_builder.add_node(\"supervisor_tools\", supervisor_tools)\n",
    "\n",
    "supervisor_builder.add_edge(START, \"supervisor\")\n",
    "supervisor_builder.add_edge(\"supervisor\", \"supervisor_tools\")\n",
    "# supervisor_tools uses Command to route back to supervisor or END\n",
    "\n",
    "supervisor_graph = supervisor_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Test the Supervisor\n",
    "\n",
    "Let's test the supervisor with a research question!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SUPERVISOR MESSAGE HISTORY:\n",
      "============================================================\n",
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "You are a research supervisor. Your job is to conduct research by calling the \"ConductResearch\" tool.\n",
      "\n",
      "<Task>\n",
      "Call the \"ConductResearch\" tool to delegate research. When you're satisfied with findings, call \"ResearchComplete\".\n",
      "</Task>\n",
      "\n",
      "<Available Tools>\n",
      "1. **ConductResearch**: Delegate research tasks to specialized sub-agents\n",
      "2. **ResearchComplete**: Indicate that research is complete\n",
      "3. **think_tool**: For reflection and strategic planning\n",
      "\n",
      "**CRITICAL: Use think_tool before calling ConductResearch to plan, and after to assess progress.**\n",
      "</Available Tools>\n",
      "\n",
      "<Instructions>\n",
      "Think like a research manager:\n",
      "\n",
      "1. **Read the question carefully** - What specific information is needed?\n",
      "2. **Decide how to delegate** - Can multiple independent angles be explored simultaneously?\n",
      "3. **After each ConductResearch call, assess** - Do I have enough? What's missing?\n",
      "</Instructions>\n",
      "\n",
      "<Hard Limits>\n",
      "- **Limit tool calls** - Stop after 3 tool calls if you cannot find the right sources\n",
      "- **Maximum 5 parallel agents per iteration**\n",
      "</Hard Limits>\n",
      "\n",
      "<Scaling Rules>\n",
      "**Simple queries** - Use a single sub-agent\n",
      "**Comparisons** - Use a sub-agent for each element being compared\n",
      "**Important**: Provide complete standalone instructions when calling ConductResearch\n",
      "</Scaling Rules>\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Recommend some chinese restaurants and indian restaurants in NYC\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'arguments': '{\"reflection\":\"This is a comparison request: the user wants restaurant recommendations for two distinct cuisines (Chinese and Indian) in NYC. I should delegate one sub-agent to focus on finding highly-rated Chinese restaurants, and another for Indian restaurants, both limited to New York City. Each agent should look for quality, popularity, and include locations and highlights. After receiving their findings, I\\'ll assess whether the selections offer variety and useful details.\"}', 'call_id': 'call_KSBuh5dIJl9mDH1GGwVz5aSi', 'name': 'think_tool', 'type': 'function_call', 'id': 'fc_028f1a9d7d5dbe1e00695df6bb196081969299eaf4c2b58c19', 'status': 'completed'}]\n",
      "Tool Calls:\n",
      "  think_tool (call_KSBuh5dIJl9mDH1GGwVz5aSi)\n",
      " Call ID: call_KSBuh5dIJl9mDH1GGwVz5aSi\n",
      "  Args:\n",
      "    reflection: This is a comparison request: the user wants restaurant recommendations for two distinct cuisines (Chinese and Indian) in NYC. I should delegate one sub-agent to focus on finding highly-rated Chinese restaurants, and another for Indian restaurants, both limited to New York City. Each agent should look for quality, popularity, and include locations and highlights. After receiving their findings, I'll assess whether the selections offer variety and useful details.\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: think_tool\n",
      "\n",
      "Reflection recorded: This is a comparison request: the user wants restaurant recommendations for two distinct cuisines (Chinese and Indian) in NYC. I should delegate one sub-agent to focus on finding highly-rated Chinese restaurants, and another for Indian restaurants, both limited to New York City. Each agent should look for quality, popularity, and include locations and highlights. After receiving their findings, I'll assess whether the selections offer variety and useful details.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'arguments': '{\"research_topic\":\"Find a list of highly-rated Chinese restaurants in NYC, including their names, locations, and a brief note on what makes each one stand out (e.g., specialty dishes, reputation, or uniqueness).\"}', 'call_id': 'call_3X676OJfKVPPFmYq3GfgImlb', 'name': 'ConductResearch', 'type': 'function_call', 'id': 'fc_028f1a9d7d5dbe1e00695df6bda9548196ab338a6e17bd406e', 'status': 'completed'}, {'arguments': '{\"research_topic\":\"Find a list of highly-rated Indian restaurants in NYC, including their names, locations, and a brief note on what makes each one stand out (e.g., specialty dishes, reputation, or uniqueness).\"}', 'call_id': 'call_ZsFYsuvtCEqdOuZrzRtWGxoW', 'name': 'ConductResearch', 'type': 'function_call', 'id': 'fc_028f1a9d7d5dbe1e00695df6be96b48196b718f537b25d5cfc', 'status': 'completed'}]\n",
      "Tool Calls:\n",
      "  ConductResearch (call_3X676OJfKVPPFmYq3GfgImlb)\n",
      " Call ID: call_3X676OJfKVPPFmYq3GfgImlb\n",
      "  Args:\n",
      "    research_topic: Find a list of highly-rated Chinese restaurants in NYC, including their names, locations, and a brief note on what makes each one stand out (e.g., specialty dishes, reputation, or uniqueness).\n",
      "  ConductResearch (call_ZsFYsuvtCEqdOuZrzRtWGxoW)\n",
      " Call ID: call_ZsFYsuvtCEqdOuZrzRtWGxoW\n",
      "  Args:\n",
      "    research_topic: Find a list of highly-rated Indian restaurants in NYC, including their names, locations, and a brief note on what makes each one stand out (e.g., specialty dishes, reputation, or uniqueness).\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: ConductResearch\n",
      "\n",
      "[{'type': 'text', 'text': 'Here are some highly-rated Chinese restaurants in New York City, each offering unique specialties and experiences:\\n\\n**Maxi\\'s Noodle**\\n- Location: 135-11 38th Ave, Flushing, NY 11354\\n- Specialty: Renowned for its oversized wontons and authentic Hong Kong-style noodle bowls. In 2024, it was named the best Chinese restaurant in the U.S. by Yelp. [1]\\n\\n**Chang Lai Fishballs & Noodles**\\n- Location: 55B Bayard St, New York, NY 10013\\n- Specialty: Famous for aromatic curry fishballs, a popular Hong Kong street snack, served with luscious rice noodles. Ranked fifth on Yelp\\'s Top 100 Chinese Restaurants list in 2024. [1]\\n\\n**Lei**\\n- Location: Doyers Street, New York, NY 10013\\n- Specialty: Offers a modern take on Chinese-American cuisine with dishes like Lady Edison Jinhua ham with Asian pears and warm sesame shao bing with butter. Recognized as one of the top NYC restaurants in 2025. [2]\\n\\n**YongChuan**\\n- Location: Lower East Side, New York, NY\\n- Specialty: Manhattan\\'s only restaurant focused on Ningbo cuisine, a seafood-centric style from Zhejiang province, with some Sichuan dishes. Known for its Ningbo cold \"smoked\" fish and yellow croaker. [3]\\n\\n**Gulp**\\n- Location: 56 E 41st Street, New York, NY 10017\\n- Specialty: A Taiwanese restaurant known for its authentic breakfast offerings and a Cantopop and Mandopop–themed bar called 929. Opened its third location in Midtown\\'s Hue House in November 2025. [4]\\n\\n**Xie Bao**\\n- Location: 133-35 Roosevelt Ave, Flushing, NY 11354\\n- Specialty: Specializes in crab dishes, particularly its signature crab roe over rice. Expanded to a second location in Hell\\'s Kitchen in 2025. [5]\\n\\n**Uluh**\\n- Location: 152A 2nd Avenue, New York, NY 10003\\n- Specialty: Known for its extensive selection of over thirty teas and a diverse menu featuring over a hundred dishes from various Chinese regions. Recognized as one of the best Chinese restaurants in NYC. [6]\\n\\n**Wo Hop**\\n- Location: 17 Mott St, New York, NY 10013\\n- Specialty: Established in 1938, it\\'s one of Chinatown\\'s oldest restaurants, celebrated for its classic Cantonese dishes. Expanded to include a street-level dining room in June 2025. [7]\\n\\n**Bonnie\\'s**\\n- Location: 398 Manhattan Ave, Brooklyn, NY 11211\\n- Specialty: Offers a modern take on Cantonese-American cuisine, blending traditional flavors with contemporary techniques in a vibrant Williamsburg setting.\\n\\n**Szechuan Mountain House**\\n- Location: 3916 Prince St, Ste G03, Queens, NY 11354\\n- Specialty: Acclaimed for its authentic Sichuan cuisine, offering bold, spicy dishes in a rustic decor that complements the immersive dining experience.\\n\\n---\\n\\n**Sources**\\n\\n[1] https://www.aol.com/nyc-noodle-shop-named-best-170523512.html?utm_source=openai  \\n[2] https://blog.resy.com/2025/12/nyc-restaurants-2025/?utm_source=openai  \\n[3] https://unearththevoyage.com/16-nyc-chinese-restaurants-specializing-in-regional-flavors/?utm_source=openai  \\n[4] https://en.wikipedia.org/wiki/Gulp_%28restaurant%29?utm_source=openai  \\n[5] https://en.wikipedia.org/wiki/Xie_Bao_%28restaurant%29?utm_source=openai  \\n[6] https://en.wikipedia.org/wiki/Uluh?utm_source=openai  \\n[7] https://en.wikipedia.org/wiki/Wo_Hop?utm_source=openai', 'annotations': [], 'id': 'msg_04c66003ec2874a900695df6e585c88193b7a025b7962a8e78'}]\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: ConductResearch\n",
      "\n",
      "[{'type': 'text', 'text': \"Here are some highly-rated Indian restaurants in New York City, each offering unique culinary experiences:\\n\\n**Semma**  \\nClosed · South Indian restaurant · $50–100 · 4.2 (1475 reviews)  \\n60 Greenwich Ave, New York, NY 10011  \\nLocated in Greenwich Village, Semma specializes in authentic South Indian cuisine under Chef Vijay Kumar. Known for its bold flavors and traditional dishes like crisp, ghee-soaked dosas, Semma was named the No. 1 restaurant in NYC for 2025 by The New York Times and holds a Michelin star. \\n\\n**HYDERABADI ZAIQA**  \\nClosed · Indian restaurant · $20–30 · 4.5 (798 reviews)  \\n366 W 52nd St, New York, NY 10019  \\nWith locations in Hell's Kitchen and Murray Hill, Hyderabadi Zaiqa is celebrated for its authentic Hyderabadi dum biryani and a menu that reflects the rich culinary traditions of Hyderabad. It was ranked 95th on The New York Times' 2024 list. \\n\\n**Bungalow**  \\nClosed · Indian restaurant · $50–100 · 4.3 (1708 reviews)  \\n24 1st Ave, New York, NY 10009  \\nLocated in the East Village, Bungalow was founded by Chef Vikas Khanna and Jimmy Rizvi in 2024. The restaurant draws inspiration from Indian country clubs and offers a menu that blends traditional and contemporary Indian dishes. \\n\\n**Kanyakumari**  \\nClosed · South Indian restaurant · $50–100 · 4.5 (746 reviews)  \\n20 E 17th St, New York, NY 10003  \\nOpened in 2024 in the Flatiron District, Kanyakumari focuses on coastal Southern Indian cuisine, offering dishes like mussels Koliwada and vada pav. It joined the Michelin Guide for New York City in June 2024. \\n\\n**Junoon**  \\nClosed · Indian restaurant · $100+ · 4.3 (4244 reviews)  \\n19 W 24 St, New York, NY 10010  \\nEstablished in 2010, Junoon offers a modern take on traditional Indian cuisine. Known for its elegant ambiance and innovative dishes, it held a Michelin star until 2019 and continues to be a staple in NYC's Indian dining scene. \\n\\n**Hindu Temple Canteen**  \\nClosed · South Indian restaurant · $10–20 · 4.6 (1986 reviews)  \\n143-09 Holly Ave, Flushing, NY 11355  \\nSituated in the basement of a Hindu temple in Flushing, Queens, Temple Canteen is renowned for its authentic South Indian vegetarian fare, including dosas and idlis, served in a cafeteria-style setting. \\n\\n---\\n\\n**Sources**\\n\\n  \", 'annotations': [], 'id': 'msg_0e67ae4308a289eb00695df6e9b4388190b107a5571fbddf97'}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'arguments': '{\"reflection\":\"The recommendations provided include detailed lists of both Chinese and Indian restaurants in NYC with names, locations, specialties, and recognitions. I should now assess whether there is enough variety in price points, geographic coverage, and cuisine styles. If these aspects are sufficiently covered and the selections seem balanced, I can recommend these findings to the user. Otherwise, I may need to conduct further targeted research.\"}', 'call_id': 'call_gomCxl8dGEliyQiX4qBINAJk', 'name': 'think_tool', 'type': 'function_call', 'id': 'fc_028f1a9d7d5dbe1e00695df6f10358819694cd75b026820c4d', 'status': 'completed'}]\n",
      "Tool Calls:\n",
      "  think_tool (call_gomCxl8dGEliyQiX4qBINAJk)\n",
      " Call ID: call_gomCxl8dGEliyQiX4qBINAJk\n",
      "  Args:\n",
      "    reflection: The recommendations provided include detailed lists of both Chinese and Indian restaurants in NYC with names, locations, specialties, and recognitions. I should now assess whether there is enough variety in price points, geographic coverage, and cuisine styles. If these aspects are sufficiently covered and the selections seem balanced, I can recommend these findings to the user. Otherwise, I may need to conduct further targeted research.\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: think_tool\n",
      "\n",
      "Reflection recorded: The recommendations provided include detailed lists of both Chinese and Indian restaurants in NYC with names, locations, specialties, and recognitions. I should now assess whether there is enough variety in price points, geographic coverage, and cuisine styles. If these aspects are sufficiently covered and the selections seem balanced, I can recommend these findings to the user. Otherwise, I may need to conduct further targeted research.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'arguments': '{}', 'call_id': 'call_HIVLKCb45zxS8ak3B4hTSoVp', 'name': 'ResearchComplete', 'type': 'function_call', 'id': 'fc_028f1a9d7d5dbe1e00695df6f3325c8196b7983669a5149046', 'status': 'completed'}]\n",
      "Tool Calls:\n",
      "  ResearchComplete (call_HIVLKCb45zxS8ak3B4hTSoVp)\n",
      " Call ID: call_HIVLKCb45zxS8ak3B4hTSoVp\n",
      "  Args:\n",
      "\n",
      "============================================================\n",
      "COLLECTED RESEARCH NOTES:\n",
      "============================================================\n",
      "\n",
      "--- Research Finding 1 ---\n",
      "Reflection recorded: This is a comparison request: the user wants restaurant recommendations for two distinct cuisines (Chinese and Indian) in NYC. I should delegate one sub-agent to focus on finding highly-rated Chinese restaurants, and another for Indian restaurants, both limited to New York City. Each agent should look for quality, popularity, and include locations and highlights. After receiving their findings, I'll assess whether the selections offer variety and useful details.\n",
      "\n",
      "--- Research Finding 2 ---\n",
      "[{'type': 'text', 'text': 'Here are some highly-rated Chinese restaurants in New York City, each offering unique specialties and experiences:\\n\\n**Maxi\\'s Noodle**\\n- Location: 135-11 38th Ave, Flushing, NY 11354\\n- Specialty: Renowned for its oversized wontons and authentic Hong Kong-style noodle bowls. In 2024, it was named the best Chinese restaurant in the U.S. by Yelp. [1]\\n\\n**Chang Lai Fishballs & Noodles**\\n- Location: 55B Bayard St, New York, NY 10013\\n- Specialty: Famous for aromatic c...\n",
      "\n",
      "--- Research Finding 3 ---\n",
      "[{'type': 'text', 'text': \"Here are some highly-rated Indian restaurants in New York City, each offering unique culinary experiences:\\n\\n**Semma**  \\nClosed · South Indian restaurant · $50–100 · 4.2 (1475 reviews)  \\n60 Greenwich Ave, New York, NY 10011  \\nLocated in Greenwich Village, Semma specializes in authentic South Indian cuisine under Chef Vijay Kumar. Known for its bold flavors and traditional dishes like crisp, ghee-soaked dosas, Semma was named the No. 1 restaurant in NYC for 2025 by ...\n",
      "\n",
      "--- Research Finding 4 ---\n",
      "Reflection recorded: The recommendations provided include detailed lists of both Chinese and Indian restaurants in NYC with names, locations, specialties, and recognitions. I should now assess whether there is enough variety in price points, geographic coverage, and cuisine styles. If these aspects are sufficiently covered and the selections seem balanced, I can recommend these findings to the user. Otherwise, I may need to conduct further targeted research.\n"
     ]
    }
   ],
   "source": [
    "# Test the supervisor\n",
    "research_brief = \"Recommend some chinese restaurants and indian restaurants in NYC\"\n",
    "\n",
    "supervisor_system_prompt = lead_researcher_prompt.format(\n",
    "    date=get_today_str(),\n",
    "    max_concurrent_research_units=MAX_CONCURRENT_RESEARCH_UNITS,\n",
    "    max_researcher_iterations=MAX_RESEARCHER_ITERATIONS\n",
    ")\n",
    "\n",
    "initial_state = {\n",
    "    \"supervisor_messages\": [\n",
    "        SystemMessage(content=supervisor_system_prompt),\n",
    "        HumanMessage(content=research_brief)\n",
    "    ],\n",
    "    \"research_brief\": research_brief,\n",
    "    \"research_iterations\": 0,\n",
    "    \"notes\": [],\n",
    "    \"raw_notes\": []\n",
    "}\n",
    "result = await supervisor_graph.ainvoke(initial_state)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"SUPERVISOR MESSAGE HISTORY:\")\n",
    "print(\"=\"*60)\n",
    "for message in result[\"supervisor_messages\"]:\n",
    "    message.pretty_print()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COLLECTED RESEARCH NOTES:\")\n",
    "print(\"=\"*60)\n",
    "for i, note in enumerate(result[\"notes\"], 1):\n",
    "    print(f\"\\n--- Research Finding {i} ---\")\n",
    "    print(note[:500] + \"...\" if len(note) > 500 else note)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Adding Human-in-the-Loop\n",
    "\n",
    "This is the full production-ready research agent!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Define Main Agent State\n",
    "\n",
    "We can now put together the State for our overall graph to track. We can share State with the supervisor by including the same keys in our overall State. This allows the supervisor to inherit information gleaned from our human feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    \"\"\"State for the complete research agent.\"\"\"\n",
    "    messages: list              # User conversation\n",
    "    research_brief: str         # Processed research goal\n",
    "    supervisor_messages: list   # Supervisor conversation\n",
    "    research_iterations: int    # Tracking iterations\n",
    "    notes: list                # Collected findings\n",
    "    raw_notes: list            # Raw notes\n",
    "    final_report: str          # Generated report\n",
    "\n",
    "class AgentInputState(TypedDict):\n",
    "    \"\"\"Input to the agent - just user messages.\"\"\"\n",
    "    messages: list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Add Human in the Loop\n",
    "\n",
    "This node uses `interrupt()` to inject human feedback on the research topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClarifyWithUser(TypedDict):\n",
    "    \"\"\"Structured output for clarification.\"\"\"\n",
    "    need_clarification: bool\n",
    "    question: str\n",
    "    verification: str\n",
    "\n",
    "clarify_with_user_instructions = \"\"\"These are the messages exchanged so far:\n",
    "<Messages>\n",
    "{messages}\n",
    "</Messages>\n",
    "\n",
    "Today's date is {date}.\n",
    "\n",
    "Assess whether you need to ask a clarifying question.\n",
    "\n",
    "If you need to ask a question:\n",
    "- Be concise while gathering necessary information\n",
    "- Don't ask for information already provided\n",
    "\n",
    "Respond in JSON with these keys:\n",
    "{{\"need_clarification\": boolean, \"question\": \"...\", \"verification\": \"...\"}}\n",
    "\n",
    "If clarification needed:\n",
    "{{\"need_clarification\": true, \"question\": \"<your question>\", \"verification\": \"\"}}\n",
    "\n",
    "If no clarification needed:\n",
    "{{\"need_clarification\": false, \"question\": \"\", \"verification\": \"<acknowledgement message>\"}}\n",
    "\"\"\"\n",
    "\n",
    "async def clarify_with_user(state: AgentState, config):\n",
    "    \"\"\"Ask clarifying questions if needed using human-in-the-loop.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # Configure model for structured clarification\n",
    "    clarification_model = (\n",
    "        get_model()\n",
    "        .with_structured_output(ClarifyWithUser)\n",
    "        .with_retry(stop_after_attempt=MAX_STRUCTURED_OUTPUT_RETRIES)\n",
    "    )\n",
    "    \n",
    "    # Analyze whether clarification is needed\n",
    "    prompt_content = clarify_with_user_instructions.format(\n",
    "        messages=get_buffer_string(messages),\n",
    "        date=get_today_str()\n",
    "    )\n",
    "    response = await clarification_model.ainvoke([HumanMessage(content=prompt_content)])\n",
    "    \n",
    "    # If clarification needed, use interrupt to pause for user input\n",
    "    if response[\"need_clarification\"]:\n",
    "        user_response = interrupt(response[\"question\"])\n",
    "        return {\"messages\": [HumanMessage(content=user_response)]}\n",
    "    else:\n",
    "        # No clarification needed\n",
    "        return {\"messages\": [AIMessage(content=response[\"verification\"])]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll create another node to take the research prompt with human feedback included, and use it to generate a high level plan. Keeping this plan available to our agent through the State key research_brief will allow our agent to stay on track even with complicated tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResearchQuestion(TypedDict):\n",
    "    \"\"\"Structured research question.\"\"\"\n",
    "    research_brief: str\n",
    "\n",
    "create_research_brief_prompt = \"\"\"Translate these messages into a detailed research question:\n",
    "\n",
    "<Messages>\n",
    "{messages}\n",
    "</Messages>\n",
    "\n",
    "Today's date is {date}.\n",
    "\n",
    "Guidelines:\n",
    "1. Maximize specificity and detail - include all user preferences\n",
    "2. Fill in unstated but necessary dimensions as open-ended\n",
    "3. Avoid unwarranted assumptions\n",
    "4. Use first person (from user's perspective)\n",
    "5. For product/travel research, prefer official sources\n",
    "\"\"\"\n",
    "\n",
    "async def write_research_brief(state: AgentState, config) -> Command[Literal[\"research_supervisor\"]]:\n",
    "    \"\"\"Transform user messages into a structured research brief.\"\"\"\n",
    "    # Configure model for structured output\n",
    "    research_model = (\n",
    "        get_model()\n",
    "        .with_structured_output(ResearchQuestion)\n",
    "        .with_retry(stop_after_attempt=MAX_STRUCTURED_OUTPUT_RETRIES)\n",
    "    )\n",
    "    \n",
    "    # Generate research brief\n",
    "    prompt_content = create_research_brief_prompt.format(\n",
    "        messages=get_buffer_string(state.get(\"messages\", [])),\n",
    "        date=get_today_str()\n",
    "    )\n",
    "    response = await research_model.ainvoke([HumanMessage(content=prompt_content)])\n",
    "    \n",
    "    # Initialize supervisor\n",
    "    supervisor_system_prompt = lead_researcher_prompt.format(\n",
    "        date=get_today_str(),\n",
    "        max_concurrent_research_units=MAX_CONCURRENT_RESEARCH_UNITS,\n",
    "        max_researcher_iterations=MAX_RESEARCHER_ITERATIONS\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"research_brief\": response[\"research_brief\"],\n",
    "        \"supervisor_messages\": {\n",
    "            \"type\": \"override\",\n",
    "            \"value\": [\n",
    "                SystemMessage(content=supervisor_system_prompt),\n",
    "                HumanMessage(content=response[\"research_brief\"])\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Format Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_report_generation_prompt = \"\"\"Based on all research conducted, create a comprehensive answer to:\n",
    "<Research Brief>\n",
    "{research_brief}\n",
    "</Research Brief>\n",
    "\n",
    "Today's date is {date}.\n",
    "\n",
    "Here are the findings:\n",
    "<Findings>\n",
    "{findings}\n",
    "</Findings>\n",
    "\n",
    "Create a detailed answer that:\n",
    "1. Is well-organized with proper headings (# for title, ## for sections)\n",
    "2. Includes specific facts from the research\n",
    "3. References sources using [Title](URL) format\n",
    "4. Provides comprehensive analysis\n",
    "5. Includes a \"Sources\" section at the end\n",
    "\n",
    "Structure your report appropriately:\n",
    "- For comparisons: intro → overview A → overview B → comparison → conclusion\n",
    "- For lists: just the list with details\n",
    "- For summaries: overview → key concepts → conclusion\n",
    "\n",
    "Use ## for section titles. Be thorough - users expect deep research.\n",
    "\"\"\"\n",
    "\n",
    "async def final_report_generation(state: AgentState, config):\n",
    "    \"\"\"Generate the final comprehensive research report.\"\"\"\n",
    "    notes = state.get(\"notes\", [])\n",
    "    findings = \"\\n\".join(notes)\n",
    "    \n",
    "    # Create report prompt\n",
    "    final_report_prompt = final_report_generation_prompt.format(\n",
    "        research_brief=state.get(\"research_brief\", \"\"),\n",
    "        messages=get_buffer_string(state.get(\"messages\", [])),\n",
    "        findings=findings,\n",
    "        date=get_today_str()\n",
    "    )\n",
    "    \n",
    "    # Generate report\n",
    "    final_report = await get_model().ainvoke([HumanMessage(content=final_report_prompt)])\n",
    "    \n",
    "    return {\n",
    "        \"final_report\": final_report.content,\n",
    "        \"messages\": [final_report],\n",
    "        \"notes\": {\"type\": \"override\", \"value\": []}\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Compile with Persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x10b70bed0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create checkpointer for interrupt/resume support\n",
    "checkpointer = MemorySaver()\n",
    "\n",
    "# Build complete research workflow\n",
    "deep_researcher_builder = StateGraph(\n",
    "    AgentState,\n",
    "    input_schema=AgentInputState\n",
    ")\n",
    "\n",
    "# Add nodes\n",
    "deep_researcher_builder.add_node(\"clarify_with_user\", clarify_with_user)\n",
    "deep_researcher_builder.add_node(\"write_research_brief\", write_research_brief)\n",
    "deep_researcher_builder.add_node(\"research_supervisor\", supervisor_graph)\n",
    "deep_researcher_builder.add_node(\"final_report_generation\", final_report_generation)\n",
    "\n",
    "# Add edges\n",
    "deep_researcher_builder.add_edge(START, \"clarify_with_user\")\n",
    "deep_researcher_builder.add_edge(\"clarify_with_user\", \"write_research_brief\")\n",
    "deep_researcher_builder.add_edge(\"write_research_brief\", \"research_supervisor\")\n",
    "deep_researcher_builder.add_edge(\"research_supervisor\", \"final_report_generation\")\n",
    "deep_researcher_builder.add_edge(\"final_report_generation\", END)\n",
    "\n",
    "# Compile with checkpointer for interrupt/resume support\n",
    "deep_research_graph = deep_researcher_builder.compile(checkpointer=checkpointer)\n",
    "deep_research_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Test HITL and Persistence\n",
    "\n",
    "Let's test the full research workflow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting research workflow...\n",
      "\n",
      "============================================================\n",
      "INTERRUPT: Clarification question detected\n",
      "============================================================\n",
      "Question: Are you looking for upscale dining, casual spots, or takeout options?\n",
      "\n",
      "Resuming with: 'Use your best judgement'\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "MAIN AGENT MESSAGE HISTORY:\n",
      "============================================================\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'type': 'text', 'text': '# Comprehensive Review: Methods and Best Practices for Responding to Open-Ended or Ambiguously Stated User Prompts (January 2026)\\n\\n## Introduction\\n\\nAddressing open-ended or ambiguous user prompts—especially when provided with minimal context—is a recurring challenge across domains such as artificial intelligence (AI), customer service, technical support, and academic research. As of January 2026, rapid advancements in prompt engineering, dialogue systems, and transparency frameworks have produced a robust set of methods, best practices, and documentation standards to systematically manage this challenge. This report synthesizes state-of-the-art research, highlighting reliable approaches, comparative frameworks, and established guidelines for ensuring thorough, relevant, and transparent responses. It also provides practical strategies for systematically documenting all assumptions and inferences made during the process.\\n\\n---\\n\\n## Reliable and Up-To-Date Methods for Handling Ambiguous Prompts\\n\\nA suite of recent advances addresses user prompts with ambiguous or minimal information. These methods draw from AI, computational linguistics, and knowledge management:\\n\\n### 1. Enhanced Clarification Frameworks (ECLAIR)\\n\\n- **What it is:** An advanced, end-to-end clarification framework that generates targeted follow-up questions for ambiguous prompts.\\n- **Key strengths:** Integrates ambiguity signals from multiple agents, offering domain-specific disambiguation.\\n- **Result:** Outperforms few-shot prompt methods in clarification accuracy and user satisfaction.\\n- [ECLAIR (Enhanced CLArification for Interactive Responses)](https://arxiv.org/abs/2503.15739?utm_source=openai)\\n\\n### 2. Iterative Disambiguation (Progressive Cutting-Search)\\n\\n- **What it is:** Applies a sequence of structured questions and proposals to iteratively reduce ambiguity.\\n- **Key strengths:** Demonstrates higher accuracy and satisfaction in coding, data analysis, and creative tasks.\\n- [Progressive Cutting-Search Approach](https://arxiv.org/abs/2505.02952?utm_source=openai)\\n\\n### 3. Retrieval-Augmented Generation (RAG)\\n\\n- **What it is:** Combines large language models (LLMs) with real-time document retrieval, so answers can be grounded in domain-specific or up-to-date sources.\\n- **Key strengths:** Increases factual accuracy and supports context-rich responses.\\n- [Prompt Engineering Overview (RAG)](https://en.wikipedia.org/wiki/Prompt_engineering?utm_source=openai)\\n\\n### 4. Chain-of-Thought Prompting (CoT)\\n\\n- **What it is:** Guides AI (and humans) to break down reasoning into explicit, step-wise intermediate steps.\\n- **Key strengths:** Substantially improves multi-step reasoning and transparency in deriving answers.\\n- [Prompt Engineering—Chain-of-Thought](https://en.wikipedia.org/wiki/Prompt_engineering?utm_source=openai)\\n\\n### 5. Multi-Agent Clarification (MAC Framework)\\n\\n- **What it is:** Coordinates multiple specialized agents to handle multi-layered ambiguities efficiently in conversation.\\n- **Key strengths:** Reduces repetitive exchanges, achieves higher task success by prompting for all required information up front.\\n- [MAC: Multi-Agent Clarification Framework](https://arxiv.org/abs/2512.13154?utm_source=openai)\\n\\n### 6. Tree of Clarifications (ToC)\\n\\n- **What it is:** Systematically constructs a branching tree of possible interpretations and disambiguations of a user prompt.\\n- **Key strengths:** Excels in few-shot scenarios and provides comprehensive, multi-faceted long-form answers.\\n- [Tree of Clarifications (ToC)](https://arxiv.org/abs/2310.14696?utm_source=openai)\\n\\n---\\n\\n## Best Practices and Guidelines for Responding to Ambiguity\\n\\nTo ensure responses are thorough, relevant, and transparent, the following best practices are endorsed by industry experts and recent literature:\\n\\n### Clarify Ambiguities Early\\n\\n– Use targeted, concise follow-up questions to surface missing details or intended contexts (\"Are you referring to X or Y?\").\\n– Frameworks such as [CLAM (Selective Clarification for Ambiguous Questions)](https://arxiv.org/abs/2212.07769?utm_source=openai) operationalize this at scale.\\n\\n### Employ Structured Language and Definitions\\n\\n– Avoid jargon, subjective, or ambiguous terms unless clearly defined.\\n– Provide definitions for any domain-specific terms or abbreviations used.\\n\\n### Offer Context and Examples\\n\\n– Provide succinct background and practical examples to anchor interpretations.\\n– This helps both the user and the respondent identify the intended direction of inquiry.\\n\\n### Use Multiple Elicitation Techniques When Possible\\n\\n– Combine interviews, document analysis, surveys, and knowledge base lookups to triangulate intent.\\n– This is particularly valuable for high-stakes or complex queries.\\n\\n### Explicitly Manage Uncertainty\\n\\n– If a specific answer cannot be given, outline the possible interpretations and state which one(s) you are addressing.\\n– Methods like [Tree of Clarifications (ToC)](https://arxiv.org/abs/2310.14696?utm_source=openai) and [Strategic Uncertainty Response Frameworks](https://rbt-practiceexam.com/exam-strategies/uncertainty-management/?utm_source=openai) formalize these options.\\n\\n### Document Assumptions Transparently\\n\\n– Note every assumption made about the user\\'s intent, background, or information needs.\\n– Consider structured log templates or explicit notation as described below.\\n\\n---\\n\\n## Frameworks for Ensuring Thoroughness, Relevance, and Transparency\\n\\nThe following established frameworks help structure, trace, and validate answers:\\n\\n### Input-Action-Output (IAO) Prompting\\n\\n- **Purpose:** Clearly delineates knowledge used (Input), actions or inferences made (Action), and final outputs (Output).\\n- **Effect:** Improves transparency, traceability, and factual consistency.\\n- [IAO Prompting](https://arxiv.org/abs/2502.03080?utm_source=openai)\\n\\n### Cognitive Prompt Architecture\\n\\n- **Purpose:** Guides inquiry through a sequence: define problem → surface assumptions → generate and critique solutions.\\n- **Effect:** Reduces errors of omission and supports completeness.\\n- [Cognitive Prompt Architecture](https://github.com/entrepeneur4lyf/cognitive-prompt-architecture?utm_source=openai)\\n\\n### Assumption Mapping and Grids\\n\\n- **Purpose:** Catalogues all assumptions, ranks them based on impact and uncertainty, and plans validation steps.\\n- **Effect:** Prioritizes careful consideration of high-impact, low-certainty assumptions.\\n- [Assumption Mapping Templates](https://www.figma.com/templates/assumption-mapping/?utm_source=openai), [Assumption Grid Decision Matrix](https://clickup.com/templates/assumption-grid-decision-matrix-t-216245570?utm_source=openai)\\n\\n### Eval Factsheets and Structured Templates\\n\\n- **Purpose:** Standardizes how evaluations, responses, and the logic behind inferences are recorded.\\n- **Effect:** Facilitates review, replication, and improvement.\\n- [Eval Factsheets](https://arxiv.org/abs/2512.04062?utm_source=openai)\\n\\n### Problem-Solving Checklists\\n\\n- **Purpose:** Checklist approach to document problem definition, information gathered, assumptions, decisions, and solutions.\\n- **Effect:** Ensures systematic, transparent, and repeatable processes.\\n- [Problem-Solving Checklist Template (MSU Denver)](https://www.msudenver.edu/wp-content/uploads/2025/10/Problem_Solving_Checklist_Template_TBC-PDF.pdf?utm_source=openai)\\n\\n---\\n\\n## Techniques and Tools for Documenting Assumptions and Inferences\\n\\nSystematic documentation is vital for transparency and knowledge transfer. Current standards include:\\n\\n### Structured Prompt Templates\\n\\n- Use modular prompt components to ensure clarity and repeatability in documentation ([OpenPrompt Framework](https://www.emergentmind.com/topics/structured-prompt-templates?utm_source=openai)).\\n\\n### Assumption Logs\\n\\n- Maintain a living document of every working assumption, rationale, and validation status.\\n- [Assumption Log Template](https://www.logtemplates.org/assumption-log-template/?utm_source=openai)\\n\\n### Process Documentation\\n\\n- Record the step-by-step approach to reasoning or problem-solving ([Atlassian Process Documentation](https://www.atlassian.com/software/confluence/resources/guides/how-to/process-documentation?utm_source=openai)).\\n\\n### YesWorkflow\\n\\n- Use code annotation to make implicit reasoning and data flows explicit ([YesWorkflow](https://arxiv.org/abs/1502.02403?utm_source=openai)).\\n\\n---\\n\\n## Comparative Analysis: When to Use Which Approach\\n\\n| **Method/Framework**                 | **Best For**                                                                | **Strengths**                                     |\\n|--------------------------------------|-----------------------------------------------------------------------------|---------------------------------------------------|\\n| ECLAIR, CLAM, MAC                    | Minimal/ambiguous user queries in chat or dialog                            | Automated, multi-turn clarification               |\\n| RAG                                  | Need to reference updated or domain-specific knowledge                      | Facts, accountability, real-time information      |\\n| Chain-of-Thought (CoT)               | Complex, multi-step reasoning tasks                                         | Step-by-step logical transparency                 |\\n| ToC, Iterative Disambiguation        | Ambiguity with multiple plausible interpretations                           | Comprehensive, multi-interpretation coverage      |\\n| Input-Action-Output, Cognitive Arch. | Ensuring transparency and systematic rationale in reasoning                 | Explicit, auditable logic                         |\\n| Assumption Logs/Mappings             | Auditing, compliance, team-based decision-making                            | Prioritized, ongoing assumption tracking          |\\n\\n---\\n\\n## Conclusion\\n\\nThe landscape for addressing open-ended or ambiguous prompts has advanced markedly as of 2026. The most reliable responses leverage a combination of interactive clarification methods (e.g., ECLAIR, MAC), retrieval and reasoning augmentation (RAG, CoT), and rigorous, transparent documentation frameworks (IAO Prompting, Assumption Mapping).\\n\\nTo ensure thoroughness, always clarify ambiguities, use structured reasoning frameworks, and make assumptions explicit. For maximal relevance and transparency, document every inference, refer to up-to-date information, and maintain systematic records using established templates and workflows.\\n\\n---\\n\\n## Sources\\n\\n- [ECLAIR: Enhanced CLArification for Interactive Responses](https://arxiv.org/abs/2503.15739?utm_source=openai)\\n- [Progressive Cutting-Search Approach](https://arxiv.org/abs/2505.02952?utm_source=openai)\\n- [Prompt Engineering Overview](https://en.wikipedia.org/wiki/Prompt_engineering?utm_source=openai)\\n- [Automated Prompt Engineering](https://aclanthology.org/2025.findings-acl.1140.pdf?utm_source=openai)\\n- [MAC: Multi-Agent Clarification Framework](https://arxiv.org/abs/2512.13154?utm_source=openai)\\n- [CLAM: Selective Clarification for Ambiguous Questions](https://arxiv.org/abs/2212.07769?utm_source=openai)\\n- [Tree of Clarifications (ToC)](https://arxiv.org/abs/2310.14696?utm_source=openai)\\n- [CLAMBER Benchmark](https://arxiv.org/abs/2405.12063?utm_source=openai)\\n- [Semi-Automated Requirement Ambiguity Resolution](https://www.sciencedirect.com/science/article/abs/pii/S0360835220305313?utm_source=openai)\\n- [CICC: Intent Clarification in Dialogues](https://arxiv.org/abs/2403.18973?utm_source=openai)\\n- [Strategic Uncertainty Response Frameworks](https://rbt-practiceexam.com/exam-strategies/uncertainty-management/?utm_source=openai)\\n- [Input-Action-Output (IAO) Prompting](https://arxiv.org/abs/2502.03080?utm_source=openai)\\n- [Cognitive Prompt Architecture](https://github.com/entrepeneur4lyf/cognitive-prompt-architecture?utm_source=openai)\\n- [Assumption Mapping Templates](https://www.figma.com/templates/assumption-mapping/?utm_source=openai)\\n- [Assumption Grid Decision Matrix](https://clickup.com/templates/assumption-grid-decision-matrix-t-216245570?utm_source=openai)\\n- [Eval Factsheets](https://arxiv.org/abs/2512.04062?utm_source=openai)\\n- [Structured Prompt Templates (OpenPrompt)](https://www.emergentmind.com/topics/structured-prompt-templates?utm_source=openai)\\n- [Process Documentation Template (Atlassian)](https://www.atlassian.com/software/confluence/resources/guides/how-to/process-documentation?utm_source=openai)\\n- [Assumption Log Template](https://www.logtemplates.org/assumption-log-template/?utm_source=openai)\\n- [YesWorkflow: Annotated Code-Based Transparency](https://arxiv.org/abs/1502.02403?utm_source=openai)\\n- [Problem-Solving Checklist Template (MSU Denver)](https://www.msudenver.edu/wp-content/uploads/2025/10/Problem_Solving_Checklist_Template_TBC-PDF.pdf?utm_source=openai)\\n\\n*(All links current as of January 7, 2026.)*', 'annotations': [], 'id': 'msg_07a05f5644ce37a700695df7536f9c8193b92948e713776280'}]\n",
      "\n",
      "============================================================\n",
      "FINAL RESEARCH REPORT:\n",
      "============================================================\n",
      "[{'type': 'text', 'text': '# Comprehensive Review: Methods and Best Practices for Responding to Open-Ended or Ambiguously Stated User Prompts (January 2026)\\n\\n## Introduction\\n\\nAddressing open-ended or ambiguous user prompts—especially when provided with minimal context—is a recurring challenge across domains such as artificial intelligence (AI), customer service, technical support, and academic research. As of January 2026, rapid advancements in prompt engineering, dialogue systems, and transparency frameworks have produced a robust set of methods, best practices, and documentation standards to systematically manage this challenge. This report synthesizes state-of-the-art research, highlighting reliable approaches, comparative frameworks, and established guidelines for ensuring thorough, relevant, and transparent responses. It also provides practical strategies for systematically documenting all assumptions and inferences made during the process.\\n\\n---\\n\\n## Reliable and Up-To-Date Methods for Handling Ambiguous Prompts\\n\\nA suite of recent advances addresses user prompts with ambiguous or minimal information. These methods draw from AI, computational linguistics, and knowledge management:\\n\\n### 1. Enhanced Clarification Frameworks (ECLAIR)\\n\\n- **What it is:** An advanced, end-to-end clarification framework that generates targeted follow-up questions for ambiguous prompts.\\n- **Key strengths:** Integrates ambiguity signals from multiple agents, offering domain-specific disambiguation.\\n- **Result:** Outperforms few-shot prompt methods in clarification accuracy and user satisfaction.\\n- [ECLAIR (Enhanced CLArification for Interactive Responses)](https://arxiv.org/abs/2503.15739?utm_source=openai)\\n\\n### 2. Iterative Disambiguation (Progressive Cutting-Search)\\n\\n- **What it is:** Applies a sequence of structured questions and proposals to iteratively reduce ambiguity.\\n- **Key strengths:** Demonstrates higher accuracy and satisfaction in coding, data analysis, and creative tasks.\\n- [Progressive Cutting-Search Approach](https://arxiv.org/abs/2505.02952?utm_source=openai)\\n\\n### 3. Retrieval-Augmented Generation (RAG)\\n\\n- **What it is:** Combines large language models (LLMs) with real-time document retrieval, so answers can be grounded in domain-specific or up-to-date sources.\\n- **Key strengths:** Increases factual accuracy and supports context-rich responses.\\n- [Prompt Engineering Overview (RAG)](https://en.wikipedia.org/wiki/Prompt_engineering?utm_source=openai)\\n\\n### 4. Chain-of-Thought Prompting (CoT)\\n\\n- **What it is:** Guides AI (and humans) to break down reasoning into explicit, step-wise intermediate steps.\\n- **Key strengths:** Substantially improves multi-step reasoning and transparency in deriving answers.\\n- [Prompt Engineering—Chain-of-Thought](https://en.wikipedia.org/wiki/Prompt_engineering?utm_source=openai)\\n\\n### 5. Multi-Agent Clarification (MAC Framework)\\n\\n- **What it is:** Coordinates multiple specialized agents to handle multi-layered ambiguities efficiently in conversation.\\n- **Key strengths:** Reduces repetitive exchanges, achieves higher task success by prompting for all required information up front.\\n- [MAC: Multi-Agent Clarification Framework](https://arxiv.org/abs/2512.13154?utm_source=openai)\\n\\n### 6. Tree of Clarifications (ToC)\\n\\n- **What it is:** Systematically constructs a branching tree of possible interpretations and disambiguations of a user prompt.\\n- **Key strengths:** Excels in few-shot scenarios and provides comprehensive, multi-faceted long-form answers.\\n- [Tree of Clarifications (ToC)](https://arxiv.org/abs/2310.14696?utm_source=openai)\\n\\n---\\n\\n## Best Practices and Guidelines for Responding to Ambiguity\\n\\nTo ensure responses are thorough, relevant, and transparent, the following best practices are endorsed by industry experts and recent literature:\\n\\n### Clarify Ambiguities Early\\n\\n– Use targeted, concise follow-up questions to surface missing details or intended contexts (\"Are you referring to X or Y?\").\\n– Frameworks such as [CLAM (Selective Clarification for Ambiguous Questions)](https://arxiv.org/abs/2212.07769?utm_source=openai) operationalize this at scale.\\n\\n### Employ Structured Language and Definitions\\n\\n– Avoid jargon, subjective, or ambiguous terms unless clearly defined.\\n– Provide definitions for any domain-specific terms or abbreviations used.\\n\\n### Offer Context and Examples\\n\\n– Provide succinct background and practical examples to anchor interpretations.\\n– This helps both the user and the respondent identify the intended direction of inquiry.\\n\\n### Use Multiple Elicitation Techniques When Possible\\n\\n– Combine interviews, document analysis, surveys, and knowledge base lookups to triangulate intent.\\n– This is particularly valuable for high-stakes or complex queries.\\n\\n### Explicitly Manage Uncertainty\\n\\n– If a specific answer cannot be given, outline the possible interpretations and state which one(s) you are addressing.\\n– Methods like [Tree of Clarifications (ToC)](https://arxiv.org/abs/2310.14696?utm_source=openai) and [Strategic Uncertainty Response Frameworks](https://rbt-practiceexam.com/exam-strategies/uncertainty-management/?utm_source=openai) formalize these options.\\n\\n### Document Assumptions Transparently\\n\\n– Note every assumption made about the user\\'s intent, background, or information needs.\\n– Consider structured log templates or explicit notation as described below.\\n\\n---\\n\\n## Frameworks for Ensuring Thoroughness, Relevance, and Transparency\\n\\nThe following established frameworks help structure, trace, and validate answers:\\n\\n### Input-Action-Output (IAO) Prompting\\n\\n- **Purpose:** Clearly delineates knowledge used (Input), actions or inferences made (Action), and final outputs (Output).\\n- **Effect:** Improves transparency, traceability, and factual consistency.\\n- [IAO Prompting](https://arxiv.org/abs/2502.03080?utm_source=openai)\\n\\n### Cognitive Prompt Architecture\\n\\n- **Purpose:** Guides inquiry through a sequence: define problem → surface assumptions → generate and critique solutions.\\n- **Effect:** Reduces errors of omission and supports completeness.\\n- [Cognitive Prompt Architecture](https://github.com/entrepeneur4lyf/cognitive-prompt-architecture?utm_source=openai)\\n\\n### Assumption Mapping and Grids\\n\\n- **Purpose:** Catalogues all assumptions, ranks them based on impact and uncertainty, and plans validation steps.\\n- **Effect:** Prioritizes careful consideration of high-impact, low-certainty assumptions.\\n- [Assumption Mapping Templates](https://www.figma.com/templates/assumption-mapping/?utm_source=openai), [Assumption Grid Decision Matrix](https://clickup.com/templates/assumption-grid-decision-matrix-t-216245570?utm_source=openai)\\n\\n### Eval Factsheets and Structured Templates\\n\\n- **Purpose:** Standardizes how evaluations, responses, and the logic behind inferences are recorded.\\n- **Effect:** Facilitates review, replication, and improvement.\\n- [Eval Factsheets](https://arxiv.org/abs/2512.04062?utm_source=openai)\\n\\n### Problem-Solving Checklists\\n\\n- **Purpose:** Checklist approach to document problem definition, information gathered, assumptions, decisions, and solutions.\\n- **Effect:** Ensures systematic, transparent, and repeatable processes.\\n- [Problem-Solving Checklist Template (MSU Denver)](https://www.msudenver.edu/wp-content/uploads/2025/10/Problem_Solving_Checklist_Template_TBC-PDF.pdf?utm_source=openai)\\n\\n---\\n\\n## Techniques and Tools for Documenting Assumptions and Inferences\\n\\nSystematic documentation is vital for transparency and knowledge transfer. Current standards include:\\n\\n### Structured Prompt Templates\\n\\n- Use modular prompt components to ensure clarity and repeatability in documentation ([OpenPrompt Framework](https://www.emergentmind.com/topics/structured-prompt-templates?utm_source=openai)).\\n\\n### Assumption Logs\\n\\n- Maintain a living document of every working assumption, rationale, and validation status.\\n- [Assumption Log Template](https://www.logtemplates.org/assumption-log-template/?utm_source=openai)\\n\\n### Process Documentation\\n\\n- Record the step-by-step approach to reasoning or problem-solving ([Atlassian Process Documentation](https://www.atlassian.com/software/confluence/resources/guides/how-to/process-documentation?utm_source=openai)).\\n\\n### YesWorkflow\\n\\n- Use code annotation to make implicit reasoning and data flows explicit ([YesWorkflow](https://arxiv.org/abs/1502.02403?utm_source=openai)).\\n\\n---\\n\\n## Comparative Analysis: When to Use Which Approach\\n\\n| **Method/Framework**                 | **Best For**                                                                | **Strengths**                                     |\\n|--------------------------------------|-----------------------------------------------------------------------------|---------------------------------------------------|\\n| ECLAIR, CLAM, MAC                    | Minimal/ambiguous user queries in chat or dialog                            | Automated, multi-turn clarification               |\\n| RAG                                  | Need to reference updated or domain-specific knowledge                      | Facts, accountability, real-time information      |\\n| Chain-of-Thought (CoT)               | Complex, multi-step reasoning tasks                                         | Step-by-step logical transparency                 |\\n| ToC, Iterative Disambiguation        | Ambiguity with multiple plausible interpretations                           | Comprehensive, multi-interpretation coverage      |\\n| Input-Action-Output, Cognitive Arch. | Ensuring transparency and systematic rationale in reasoning                 | Explicit, auditable logic                         |\\n| Assumption Logs/Mappings             | Auditing, compliance, team-based decision-making                            | Prioritized, ongoing assumption tracking          |\\n\\n---\\n\\n## Conclusion\\n\\nThe landscape for addressing open-ended or ambiguous prompts has advanced markedly as of 2026. The most reliable responses leverage a combination of interactive clarification methods (e.g., ECLAIR, MAC), retrieval and reasoning augmentation (RAG, CoT), and rigorous, transparent documentation frameworks (IAO Prompting, Assumption Mapping).\\n\\nTo ensure thoroughness, always clarify ambiguities, use structured reasoning frameworks, and make assumptions explicit. For maximal relevance and transparency, document every inference, refer to up-to-date information, and maintain systematic records using established templates and workflows.\\n\\n---\\n\\n## Sources\\n\\n- [ECLAIR: Enhanced CLArification for Interactive Responses](https://arxiv.org/abs/2503.15739?utm_source=openai)\\n- [Progressive Cutting-Search Approach](https://arxiv.org/abs/2505.02952?utm_source=openai)\\n- [Prompt Engineering Overview](https://en.wikipedia.org/wiki/Prompt_engineering?utm_source=openai)\\n- [Automated Prompt Engineering](https://aclanthology.org/2025.findings-acl.1140.pdf?utm_source=openai)\\n- [MAC: Multi-Agent Clarification Framework](https://arxiv.org/abs/2512.13154?utm_source=openai)\\n- [CLAM: Selective Clarification for Ambiguous Questions](https://arxiv.org/abs/2212.07769?utm_source=openai)\\n- [Tree of Clarifications (ToC)](https://arxiv.org/abs/2310.14696?utm_source=openai)\\n- [CLAMBER Benchmark](https://arxiv.org/abs/2405.12063?utm_source=openai)\\n- [Semi-Automated Requirement Ambiguity Resolution](https://www.sciencedirect.com/science/article/abs/pii/S0360835220305313?utm_source=openai)\\n- [CICC: Intent Clarification in Dialogues](https://arxiv.org/abs/2403.18973?utm_source=openai)\\n- [Strategic Uncertainty Response Frameworks](https://rbt-practiceexam.com/exam-strategies/uncertainty-management/?utm_source=openai)\\n- [Input-Action-Output (IAO) Prompting](https://arxiv.org/abs/2502.03080?utm_source=openai)\\n- [Cognitive Prompt Architecture](https://github.com/entrepeneur4lyf/cognitive-prompt-architecture?utm_source=openai)\\n- [Assumption Mapping Templates](https://www.figma.com/templates/assumption-mapping/?utm_source=openai)\\n- [Assumption Grid Decision Matrix](https://clickup.com/templates/assumption-grid-decision-matrix-t-216245570?utm_source=openai)\\n- [Eval Factsheets](https://arxiv.org/abs/2512.04062?utm_source=openai)\\n- [Structured Prompt Templates (OpenPrompt)](https://www.emergentmind.com/topics/structured-prompt-templates?utm_source=openai)\\n- [Process Documentation Template (Atlassian)](https://www.atlassian.com/software/confluence/resources/guides/how-to/process-documentation?utm_source=openai)\\n- [Assumption Log Template](https://www.logtemplates.org/assumption-log-template/?utm_source=openai)\\n- [YesWorkflow: Annotated Code-Based Transparency](https://arxiv.org/abs/1502.02403?utm_source=openai)\\n- [Problem-Solving Checklist Template (MSU Denver)](https://www.msudenver.edu/wp-content/uploads/2025/10/Problem_Solving_Checklist_Template_TBC-PDF.pdf?utm_source=openai)\\n\\n*(All links current as of January 7, 2026.)*', 'annotations': [], 'id': 'msg_07a05f5644ce37a700695df7536f9c8193b92948e713776280'}]\n"
     ]
    }
   ],
   "source": [
    "# Test complete workflow\n",
    "import uuid\n",
    "\n",
    "test_query = \"Recommend the best Chinese restaurants in Manhattan\"\n",
    "\n",
    "initial_state = {\n",
    "    \"messages\": [HumanMessage(content=test_query)]\n",
    "}\n",
    "\n",
    "# Create config with thread_id for checkpointing\n",
    "config = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\n",
    "\n",
    "# First invocation - will pause at interrupt if clarification needed\n",
    "print(\"Starting research workflow...\")\n",
    "result = await deep_research_graph.ainvoke(initial_state, config=config)\n",
    "\n",
    "# Check if we hit an interrupt\n",
    "if \"__interrupt__\" in result:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"INTERRUPT: Clarification question detected\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Get the state to see the interrupt details\n",
    "    state_snapshot = deep_research_graph.get_state(config)\n",
    "    \n",
    "    # Show the interrupt value (the clarification question)\n",
    "    if hasattr(state_snapshot, 'tasks') and state_snapshot.tasks:\n",
    "        for task in state_snapshot.tasks:\n",
    "            if hasattr(task, 'interrupts') and task.interrupts:\n",
    "                for interrupt_info in task.interrupts:\n",
    "                    print(f\"Question: {interrupt_info.value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nResuming with: 'Use your best judgement'\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "# Resume from interrupt with our response\n",
    "result = await deep_research_graph.ainvoke(Command(resume=\"Use your best judgement\"), config=config)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL RESEARCH REPORT:\")\n",
    "print(\"=\"*60)\n",
    "print(result[\"final_report\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
