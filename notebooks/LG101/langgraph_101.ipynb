{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangGraph 101: Building Your First Agent\n",
    "\n",
    "Welcome to LangGraph 101! This notebook will walk you through the core concepts of building agents with LangChain and LangGraph.\n",
    "\n",
    "**What you'll learn:**\n",
    "- How to interact with language models\n",
    "- Working with messages and conversation\n",
    "- Adding tools to extend LLM capabilities\n",
    "- Building an agent that can reason and act\n",
    "- Adding memory to maintain context\n",
    "- Streaming responses for better UX\n",
    "<br> \n",
    "<br> \n",
    "---\n",
    "<br> \n",
    "\n",
    "> **Note:** This tutorial uses LangChain v1 (alpha), which provides the easiest way to start building with LLMs. LangChain agents are built on top of LangGraph, providing durable execution, streaming, human-in-the-loop, and persistence out of the box."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Setup & Installation\n",
    "\n",
    "First, let's install the necessary packages and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages \n",
    "# Run uv sync to install the packages or run:\n",
    "# !pip install --pre -U langchain langchain-anthropic langchain-openai python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intialize your LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add project root to Python path so we can import from utils module\n",
    "import sys\n",
    "from pathlib import Path\n",
    "project_root = Path().resolve().parent.parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Import model from centralized utils module\n",
    "# This avoids code duplication across notebooks and uses consistent model configuration\n",
    "from utils.models import model\n",
    "\n",
    "# Alternative: If you want to define the model inline instead of using centralized config, uncomment below:\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv(dotenv_path=\"../.env\", override=True)\n",
    "# from langchain.chat_models import init_chat_model\n",
    "# model = init_chat_model(\"openai:o3-mini\")\n",
    "\n",
    "# Note: For other providers (Azure, Bedrock, Vertex AI), update utils/models.py \n",
    "# See utils/models.py for detailed instructions on switching LLM providers\n",
    "\n",
    "\n",
    "# Suppress warning for uuid v7 for simple examples without thread id's\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', message='LangSmith now uses UUID v7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Your First LLM Call\n",
    "\n",
    "LangChain provides a **standard model interface** that works across all providers. This means you can easily swap between OpenAI, Anthropic, Google, and other providers without changing your code.\n",
    "\n",
    "Let's start by initializing a chat model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LangChain is an open-source framework designed to help developers build applications powered by large language models (LLMs). It makes it easier to chain together multiple components—like prompts, reasoning modules, memory, and external tools—into a single coherent workflow. This chaining allows you to create more sophisticated systems such as chatbots, question-answering agents, and other applications that need to manage complex interactions, contextual memory, or multi-step reasoning.\n",
      "\n",
      "Key aspects of LangChain include:\n",
      "\n",
      "1. Modular Chains: It provides an intuitive way to link together different pieces (e.g., a prompt generator, an LLM, and a response processor) to form chains that represent end-to-end tasks.\n",
      "2. Memory Management: LangChain supports the incorporation of conversation or session memory, allowing systems to maintain context over multiple interactions.\n",
      "3. Tool Integration: It can integrate with other tools (like databases, APIs, or search engines) to augment the capabilities of an LLM-based application.\n",
      "4. Flexibility: Whether you’re building a simple question-answering bot or a complex agent that interacts with various systems, LangChain offers modular building blocks to accelerate development.\n",
      "\n",
      "By abstracting much of the complexity of managing LLM interactions and integrating external resources, LangChain helps developers prototype and deploy robust language-driven applications more efficiently.\n"
     ]
    }
   ],
   "source": [
    "# Make your first call!\n",
    "response = model.invoke(\"What is LangChain?\")\n",
    "response.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Takeaway:\n",
    "- `init_chat_model()` gives you a standardized interface to any LLM provider\n",
    "- `.invoke()` sends a message and returns a response\n",
    "- No provider lock-in - swap models easily!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Understanding Messages\n",
    "\n",
    "**Messages** are the fundamental unit of context for models in LangChain. They represent the input and output of models, carrying both content and metadata.\n",
    "\n",
    "There are different message types:\n",
    "- **SystemMessage** - Instructions for how the model should behave\n",
    "- **HumanMessage** - User input\n",
    "- **AIMessage** - Model responses\n",
    "- **ToolMessage** - Results from tool executions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "An agent is an entity—often a computer program, robot, or software module—that perceives its environment, makes decisions, and takes actions in order to achieve specific goals. Think of it as a self-contained “actor” that:\n",
      "\n",
      "1. Sees what’s happening (through sensors, input data, etc.),\n",
      "2. Thinks about what to do (using rules, algorithms, or learned behavior),\n",
      "3. Acts on its environment (by moving, sending messages, or triggering other processes).\n",
      "\n",
      "For example, in artificial intelligence, a self-driving car is an agent: it continuously gathers data about its surroundings (like road signs and other vehicles), processes that information to decide on the best action (such as braking or turning), and then controls the car accordingly. Agents can work individually or as part of a group in systems known as multi-agent systems.\n"
     ]
    }
   ],
   "source": [
    "from langchain.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "# Create a conversation with different message types\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful AI assistant that explains technical concepts simply.\"),\n",
    "    HumanMessage(content=\"What is an agent?\"),\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)\n",
    "response.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-turn Conversations\n",
    "\n",
    "Messages make it easy to maintain conversation history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Consider a robot vacuum cleaner often used in homes. Here's how it functions as an agent:\n",
      "\n",
      "1. It perceives its environment using sensors to detect walls, furniture, and even dirt.\n",
      "2. It processes this information using built-in algorithms to decide its next move (for example, identifying areas that haven't been cleaned or avoiding obstacles).\n",
      "3. It acts by moving around the room, vacuuming surfaces, and adjusting its cleaning route on the fly.\n",
      "\n",
      "This robot vacuum cleaner is autonomous—it continually observes its surroundings, makes decisions based on what it senses, and takes actions to efficiently clean the space. This exemplifies how an agent operates by perceiving its environment, processing data, and acting on its goals.\n"
     ]
    }
   ],
   "source": [
    "# Continue the conversation\n",
    "messages.append(response)  # Add AI response to history\n",
    "messages.append(HumanMessage(content=\"Can you give me an example?\"))\n",
    "\n",
    "response = model.invoke(messages)\n",
    "response.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Takeaway:\n",
    "- Messages represent the conversation history\n",
    "- SystemMessage sets the model's behavior\n",
    "- Build multi-turn conversations by appending messages to a list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Adding Tools - Extending LLM Capabilities\n",
    "\n",
    "LLMs are great at language, but they can't access external data or perform actions. **Tools** extend their capabilities. You can give an LLM a list of tools, and when it needs one, it will specify which tool to call. Your job is to execute the tool and feed the results back to the LLM so it can decide what to do next.\n",
    "\n",
    "You can create a tool just by writing a Python function with a clear description. LangChain's `@tool` decorator handles formatting the function's information in the LLM's desired format.  \n",
    "\n",
    "Let's create some simple tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"temperature_fahrenheit\": 33.5, \"weather_code\": 2}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "# Basic hardcoded tool\n",
    "@tool\n",
    "def search_movies(genre: str) -> str:\n",
    "    \"\"\"Search for movies by genre.\"\"\"\n",
    "    # In a real app, this would query a movie database\n",
    "    movies = {\n",
    "        \"sci-fi\": \"Dune, Interstellar, Blade Runner 2049\",\n",
    "        \"comedy\": \"The Grand Budapest Hotel, Superbad, Knives Out\",\n",
    "        \"action\": \"Mad Max: Fury Road, John Wick, Mission Impossible\"\n",
    "    }\n",
    "    return movies.get(genre.lower(), \"No movies found for that genre\")\n",
    "\n",
    "# More realistic tool that calls an API\n",
    "@tool\n",
    "def get_weather(latitude: float, longitude: float) -> str:\n",
    "    \"\"\"Get current temperature in Fahrenheit and weather code for given coordinates.\n",
    "\n",
    "    Args:\n",
    "        latitude: Latitude coordinate\n",
    "        longitude: Longitude coordinate\n",
    "\n",
    "    Returns:\n",
    "        JSON string with temperature_fahrenheit and weather_code (do not include the code in your response, translate it to plain English)\n",
    "    \"\"\"\n",
    "    url = \"https://api.open-meteo.com/v1/forecast\"\n",
    "    params = {\n",
    "        \"latitude\": latitude,\n",
    "        \"longitude\": longitude,\n",
    "        \"current\": \"temperature_2m,weather_code\",\n",
    "        \"temperature_unit\": \"fahrenheit\"\n",
    "    }\n",
    "\n",
    "    weather = requests.get(url, params=params).json()[\"current\"]\n",
    "    temperature = weather[\"temperature_2m\"]\n",
    "    weather_code = weather[\"weather_code\"]\n",
    "    result = {\n",
    "        \"temperature_fahrenheit\": temperature,\n",
    "        \"weather_code\": weather_code\n",
    "    }\n",
    "\n",
    "    return json.dumps(result)\n",
    "\n",
    "\n",
    "\n",
    "# Test a tool directly with SF's coordinates\n",
    "print(get_weather.invoke({\"latitude\": 37.77, \"longitude\": 122.42}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool Calling (Function Calling)\n",
    "\n",
    "Now let's give these tools to the model using `.bind_tools()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool calls: [{'name': 'get_weather', 'args': {'latitude': 47.6, 'longitude': -122.33}, 'id': 'call_MMRdnaAOkTuSRtBjobG9TiKc', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "# Bind tools to the model\n",
    "tools = [get_weather, search_movies]\n",
    "model_with_tools = model.bind_tools(tools)\n",
    "message = \"What's the weather like in Seattle? (Seattle's coordinates are approximately 47.6° N latitude and 122.33° W longitude) \"\n",
    "\n",
    "# The model can now decide to call tools\n",
    "response = model_with_tools.invoke(message)\n",
    "\n",
    "# Check if the model wants to call a tool\n",
    "print(\"Tool calls:\", response.tool_calls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model returns a **tool call** request with:\n",
    "- `name`: Which tool to call\n",
    "- `args`: Arguments to pass to the tool\n",
    "- `id`: Unique identifier for tracking\n",
    "\n",
    "Let's execute the tool and continue the conversation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "It's about 40°F, and the weather in Seattle is experiencing moderate drizzle.\n"
     ]
    }
   ],
   "source": [
    "from langchain.messages import ToolMessage\n",
    "\n",
    "# Execute the tool call\n",
    "if response.tool_calls:\n",
    "    tool_call = response.tool_calls[0]\n",
    "\n",
    "    # Call the actual tool\n",
    "    if tool_call[\"name\"] == \"get_weather\":\n",
    "        result = get_weather.invoke(tool_call[\"args\"])\n",
    "\n",
    "    elif tool_call[\"name\"] == \"search_movies\":\n",
    "        result = search_movies.invoke(tool_call[\"args\"])\n",
    "\n",
    "    # Create a ToolMessage with the result\n",
    "    tool_message = ToolMessage(\n",
    "        content=result,\n",
    "        tool_call_id=tool_call[\"id\"]\n",
    "    )\n",
    "\n",
    "    # Continue the conversation with the tool result\n",
    "    final_response = model_with_tools.invoke([\n",
    "        HumanMessage(content=message),\n",
    "        response,\n",
    "        tool_message\n",
    "    ])\n",
    "\n",
    "    final_response.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Takeaway:\n",
    "- Tools are Python functions decorated with `@tool`\n",
    "- Good descriptions help the model know when to use each tool\n",
    "- Tool calling flow: Model requests tool → Execute tool → Return result → Model synthesizes final response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Building Your First Agent with `create_agent()`\n",
    "\n",
    "Manually defining a specific sequence of LLM calls and tool calls is tedious and inflexible. Instead, we can use an **agent** that runs this loop:\n",
    "1. Model decides which tool to call (if any)\n",
    "2. Tool gets executed\n",
    "3. Result goes back to model\n",
    "4. Repeat until task is complete\n",
    "\n",
    "LangChain makes this easy with `create_agent()` - **build an agent in ~10 lines of code!**\n",
    "The prebuilt agent handles running the loop described above - you just specify the system prompt and tools. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What's the weather in NYC? (40.71° N, 74.01° W) Also recommend some sci-fi movies.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_weather (call_qLf3IvZRzU761rP2jI37gJNc)\n",
      " Call ID: call_qLf3IvZRzU761rP2jI37gJNc\n",
      "  Args:\n",
      "    latitude: 40.71\n",
      "    longitude: -74.01\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_weather\n",
      "\n",
      "{\"temperature_fahrenheit\": 48.1, \"weather_code\": 2}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  search_movies (call_aFKNcYMRS64eFevh09LjCxyd)\n",
      " Call ID: call_aFKNcYMRS64eFevh09LjCxyd\n",
      "  Args:\n",
      "    genre: sci-fi\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: search_movies\n",
      "\n",
      "Dune, Interstellar, Blade Runner 2049\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The current temperature in NYC is about 48°F with partly cloudy conditions. As for sci-fi movies, here are a few recommendations: Dune, Interstellar, and Blade Runner 2049. Enjoy your day!\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "# Create an agent with tools\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[get_weather, search_movies],\n",
    "    system_prompt=\"You are a helpful assistant that can check weather and recommend movies.\"\n",
    ")\n",
    "\n",
    "# Use the agent\n",
    "result = agent.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"What's the weather in NYC? (40.71° N, 74.01° W) Also recommend some sci-fi movies.\")]\n",
    "})\n",
    "\n",
    "# Print the final response\n",
    "for message in result[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What just happened?\n",
    "\n",
    "The agent automatically:\n",
    "1. Analyzed the user's request\n",
    "2. Called `get_weather(\"NYC\")`\n",
    "3. Called `search_movies(\"sci-fi\")`\n",
    "4. Synthesized the results into a natural response\n",
    "\n",
    "Let's visualize the agent's structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x112df4690>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Takeaway:\n",
    "- `create_agent()` builds a complete agent in ~10 lines\n",
    "- The agent automatically handles the reasoning → action → observation loop\n",
    "- Built on LangGraph for production features (persistence, streaming, human-in-the-loop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Adding Memory & State\n",
    "\n",
    "Right now, each agent invocation is independent. Let's add **memory** so the agent can maintain context across multiple interactions.\n",
    "\n",
    "LangGraph uses **checkpointers** to save and restore state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 1: Hi Alice! Since you've mentioned your love for sci-fi movies, here are some top picks you might enjoy:\n",
      "\n",
      "• Dune  \n",
      "• Interstellar  \n",
      "• Blade Runner 2049\n",
      "\n",
      "Let me know if you'd like more recommendations or details about any of these movies!\n",
      "\n",
      "Response 2: Your name is Alice, and you love sci-fi movies!\n"
     ]
    }
   ],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langsmith import uuid7\n",
    "\n",
    "# Create a checkpointer for memory\n",
    "checkpointer = MemorySaver()\n",
    "\n",
    "# Create an agent with memory\n",
    "agent_with_memory = create_agent(\n",
    "    model=model,\n",
    "    tools=[get_weather, search_movies],\n",
    "    system_prompt=\"You are a helpful assistant.\",\n",
    "    checkpointer=checkpointer\n",
    ")\n",
    "\n",
    "# Create a thread for this conversation\n",
    "config = {\"configurable\": {\"thread_id\": uuid7()}}\n",
    "\n",
    "# First interaction\n",
    "result1 = agent_with_memory.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"My name is Alice and I love sci-fi movies.\"}]},\n",
    "    config=config\n",
    ")\n",
    "\n",
    "print(\"Response 1:\", result1[\"messages\"][-1].content)\n",
    "\n",
    "# Second interaction - the agent remembers!\n",
    "result2 = agent_with_memory.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What's my name and what movies do I like?\"}]},\n",
    "    config=config\n",
    ")\n",
    "print(\"\\nResponse 2:\", result2[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding State & Threads\n",
    "\n",
    "- **State**: The agent's \"memory\" - includes message history and any custom data\n",
    "- **Thread**: A conversation session identified by `thread_id`\n",
    "- **Checkpointer**: Saves state after each step, enabling memory and error recovery\n",
    "\n",
    "Each thread is independent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New thread response: I don't actually know your name! Could you please tell me what you'd like to be called?\n"
     ]
    }
   ],
   "source": [
    "# New thread - agent won't remember Alice\n",
    "new_config_with_new_thread_id = {\"configurable\": {\"thread_id\": uuid7()}}\n",
    "\n",
    "result3 = agent_with_memory.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What's my name?\"}]},\n",
    "    config=new_config_with_new_thread_id\n",
    ")\n",
    "print(\"New thread response:\", result3[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Takeaway:\n",
    "- Checkpointers enable memory across interactions\n",
    "- Thread IDs separate different conversations\n",
    "- State persists automatically - no manual state management needed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Streaming for Better UX\n",
    "\n",
    "LLMs can take a while to respond. **Streaming** shows progress in real-time, dramatically improving user experience.\n",
    "\n",
    "LangChain supports multiple streaming modes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming Agent Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming agent steps:\n",
      "\n",
      "Step: model\n",
      "   Tool call: get_weather\n",
      "\n",
      "Step: tools\n",
      "   Content: {\"temperature_fahrenheit\": 31.1, \"weather_code\": 56}\n",
      "\n",
      "Step: model\n",
      "   Content: The current temperature in Boston is about 31°F with weather conditions indicating freezing drizzle.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Stream agent progress with stream_mode=\"updates\"\n",
    "print(\"Streaming agent steps:\\n\")\n",
    "\n",
    "for chunk in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What's the weather in Boston? (42.36° N, 71.06° W) \"}]},\n",
    "    stream_mode=\"updates\"\n",
    "):\n",
    "    for node_name, data in chunk.items():\n",
    "        print(f\"Step: {node_name}\")\n",
    "        if \"messages\" in data:\n",
    "            message = data[\"messages\"][-1]\n",
    "            if hasattr(message, 'tool_calls') and message.tool_calls:\n",
    "                print(f\"   Tool call: {message.tool_calls[0]['name']}\")\n",
    "            elif hasattr(message, 'content'):\n",
    "                print(f\"   Content: {message.content[:100]}...\" if len(message.content) > 100 else f\"   Content: {message.content}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming LLM Tokens\n",
    "\n",
    "For a ChatGPT-like experience, stream tokens as they're generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming tokens:\n",
      "\n",
      "LangGraph is a framework that streamlines the creation and management of complex workflows with language models by using a graph-based approach.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Stream tokens with stream_mode=\"messages\"\n",
    "print(\"Streaming tokens:\\n\")\n",
    "\n",
    "for token, metadata in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Tell me about LangGraph in one sentence.\"}]},\n",
    "    stream_mode=\"messages\"\n",
    "):\n",
    "    # Only print content from the model node\n",
    "    if metadata.get('langgraph_node') == 'model':\n",
    "        # Get text from content blocks\n",
    "        for block in token.content_blocks:\n",
    "            if block.get('type') == 'text' and block.get('text'):\n",
    "                print(block['text'], end='', flush=True)\n",
    "\n",
    "print(\"\\n\")  # New line at the end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Takeaway:\n",
    "- `stream_mode=\"updates\"` - See each agent step (useful for debugging)\n",
    "- `stream_mode=\"messages\"` - Stream LLM tokens (ChatGPT-like UX)\n",
    "- Streaming is built-in - no extra setup required!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Putting It All Together - A Practical Example\n",
    "\n",
    "Let's build a more realistic agent that combines everything we've learned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "PERSONAL ASSISTANT DEMO\n",
      "==================================================\n",
      "\n",
      "User: Hi, I'm Alice. Can you check my preferences and recommend a movie?\n",
      "\n",
      "Assistant: Based on your preferences, you might enjoy \"Arrival,\" \"Ex Machina,\" or \"The Martian.\" Let me know if you'd like more details on any of these films!\n",
      "\n",
      "User: Also, what's the weather like in San Francisco? (37.77° N, 122.42° W) \n",
      "\n",
      "Assistant: The current temperature in San Francisco is about 50°F, and the skies are clear. Let me know if you need anything else!\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Create more realistic tools\n",
    "@tool\n",
    "def get_user_preferences(user_id: str) -> str:\n",
    "    \"\"\"Get a user's saved preferences.\"\"\"\n",
    "    # Simulate a user database\n",
    "    preferences = {\n",
    "        \"alice\": \"Loves sci-fi movies, prefers warm weather destinations\",\n",
    "        \"bob\": \"Enjoys comedy films, likes cold climates for travel\"\n",
    "    }\n",
    "    return preferences.get(user_id.lower(), \"No preferences found\")\n",
    "\n",
    "@tool\n",
    "def book_recommendation(genre: str, user_preferences: str = \"\") -> str:\n",
    "    \"\"\"Get personalized movie recommendations based on genre and user preferences.\"\"\"\n",
    "    recommendations = {\n",
    "        \"sci-fi\": \"Based on your preferences, try: Arrival, Ex Machina, or The Martian\",\n",
    "        \"comedy\": \"Based on your preferences, try: The Big Lebowski, Anchorman, or Bridesmaids\"\n",
    "    }\n",
    "    return recommendations.get(genre.lower(), \"No recommendations available\")\n",
    "\n",
    "# Create a helpful assistant agent\n",
    "assistant = create_agent(\n",
    "    model=model,\n",
    "    tools=[get_weather, get_user_preferences, book_recommendation],\n",
    "    system_prompt=\"\"\"You are a helpful personal assistant.\n",
    "\n",
    "    You can:\n",
    "    - Check weather for any city\n",
    "    - Look up user preferences\n",
    "    - Recommend movies based on preferences\n",
    "\n",
    "    Always be friendly and personalize your responses based on user preferences.\"\"\",\n",
    "    checkpointer=MemorySaver()\n",
    ")\n",
    "\n",
    "# Demo conversation\n",
    "config = {\"configurable\": {\"thread_id\": uuid7()}}\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"PERSONAL ASSISTANT DEMO\")\n",
    "print(\"=\" * 50 + \"\\n\")\n",
    "\n",
    "# Interaction 1\n",
    "print(\"User: Hi, I'm Alice. Can you check my preferences and recommend a movie?\\n\")\n",
    "result = assistant.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Hi, I'm Alice. Can you check my preferences and recommend a movie?\"}]},\n",
    "    config=config\n",
    ")\n",
    "print(f\"Assistant: {result['messages'][-1].content}\\n\")\n",
    "\n",
    "# Interaction 2\n",
    "print(\"User: Also, what's the weather like in San Francisco? (37.77° N, 122.42° W) \\n\")\n",
    "result = assistant.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Also, what's the weather like in San Francisco? (37.77° N, 122.42° W) \"}]},\n",
    "    config=config\n",
    ")\n",
    "print(f\"Assistant: {result['messages'][-1].content}\\n\")\n",
    "\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Next Steps - Exploring LangGraph Primitives\n",
    "\n",
    "We've been using `create_agent()`, which is built on **LangGraph**. LangGraph gives you full control over agent behavior using three core primitives:\n",
    "\n",
    "### Core LangGraph Concepts:\n",
    "\n",
    "1. **State** \n",
    "   - Shared data structure passed between nodes\n",
    "   - Represents the agent's \"memory\"\n",
    "   - Can include messages, custom data, etc.\n",
    "\n",
    "2. **Nodes** \n",
    "   - Python functions that process state\n",
    "   - Each node performs a specific task\n",
    "   - Examples: call LLM, execute tool, validate input\n",
    "\n",
    "3. **Edges** \n",
    "   - Define flow between nodes\n",
    "   - Can be normal (always go to next node)\n",
    "   - Or conditional (decide based on logic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When to use `create_agent()` vs custom LangGraph?\n",
    "\n",
    "**Use `create_agent()` when:**\n",
    "- Building standard ReAct-style agents\n",
    "- You need quick prototyping\n",
    "- Default behavior works for your use case\n",
    "\n",
    "**Use custom LangGraph when:**\n",
    "- You need custom control flow (e.g., approval workflows)\n",
    "- Building multi-agent systems\n",
    "- Implementing human-in-the-loop patterns\n",
    "- Complex state management requirements\n",
    "\n",
    "For more advanced patterns, check out:\n",
    "- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)\n",
    "- [LangChain Academy](https://academy.langchain.com/)\n",
    "- The `multi_agent.ipynb` notebook in this repo (LangGraph 201)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a ReAct Agent from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To explore how LangGraph's primitives work, let's rebuild the agent we created above, but without `create_agent()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our chatbot is simple - just an LLM with some associated tools - so all we need to keep in our state is a list of human messages, AI messages, and tool messages that grows as the conversation goes on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from typing import Annotated, List\n",
    "from langgraph.graph.message import AnyMessage, add_messages\n",
    "from langgraph.managed.is_last_step import RemainingSteps\n",
    "\n",
    "class State(TypedDict):\n",
    "    # Contains the full conversation history as it grows during the conversation\n",
    "    messages: Annotated[List[AnyMessage], add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nodes\n",
    "\n",
    "We can reuse the tools we defined above. However, we need to create a node that handles tool calls and formats the results as `ToolMessage` objects for the LLM to work with. Instead of defining the node ourselves, we'll use LangGraph's prebuild `ToolNode`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "# Node\n",
    "tools = [search_movies, get_weather]\n",
    "tool_node = ToolNode(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create our node for the main assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assistant(state: State):\n",
    "    # Create a list of messages to send to the LLM, beginning with our fixed system prompt\n",
    "    system_prompt = \"You are a helpful assistant that can check weather and recommend movies.\"\n",
    "    all_messages = [SystemMessage(system_prompt)] + state[\"messages\"]\n",
    "    # Invoke the LLM\n",
    "    response = model_with_tools.invoke(all_messages)\n",
    "    # Update the state with the response from the LLM\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to define a control flow that connects between our defined nodes, and that's where the concept of edges come in.\n",
    "\n",
    "**Edges are connections between nodes. They define the flow of the graph.**\n",
    "* **Normal edges** are deterministic and always go from one node to its defined target\n",
    "* **Conditional edges** are used to dynamically route between nodes, implemented as functions that return the next node to visit based upon some logic. \n",
    "\n",
    "In this case, we want a **conditional edge** from our subagent that determines whether to: \n",
    "- Invoke tools, or,\n",
    "- Route to the end if user query has been finished "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditional edge that determines whether to continue or not\n",
    "def should_continue(state: State):\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    # The LLM wants to make tool calls, we should execute them and continue\n",
    "    if last_message.tool_calls:\n",
    "        return \"continue\"\n",
    "    # The LLM returned a response instead of tool calls, we're finished\n",
    "    # Otherwise if there is, we continue\n",
    "    else:\n",
    "        return \"end\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile Graph!\n",
    "\n",
    "Now that we've defined our state, nodes, and conditional edge let's put it all together and construct our react agent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x11371a470>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# Start by defining a builder with our State class\n",
    "builder = StateGraph(State)\n",
    "\n",
    "# Add nodes\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tool_node\", tool_node)\n",
    "\n",
    "\n",
    "# Add edges\n",
    "# First, we define the start node. The query will always route to the assistant node first.\n",
    "builder.add_edge(START, \"assistant\")\n",
    "\n",
    "# Add in the conditional edge after we call the LLM\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    should_continue,\n",
    "    {\n",
    "        # If `continue`, then we call the tool node.\n",
    "        \"continue\": \"tool_node\",\n",
    "        # Otherwise we finish.\n",
    "        \"end\": END,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Always return to the LLM after calling tools\n",
    "builder.add_edge(\"tool_node\", \"assistant\")\n",
    "\n",
    "agent = builder.compile(name=\"agent\")\n",
    "agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have successfully rebuilt a ReAct agent from scratch identical to the basic one we made using `create_agent`. Let's try it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is the weather in SF today (37.77° N, 122.42° W), and what are some good Sci-Fi movies?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_weather (call_uhl6mqdvuBdy85b8irPD04Bd)\n",
      " Call ID: call_uhl6mqdvuBdy85b8irPD04Bd\n",
      "  Args:\n",
      "    latitude: 37.77\n",
      "    longitude: -122.42\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_weather\n",
      "\n",
      "{\"temperature_fahrenheit\": 50.3, \"weather_code\": 0}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  search_movies (call_BxLS54GF03emNj7hmmtwTLSq)\n",
      " Call ID: call_BxLS54GF03emNj7hmmtwTLSq\n",
      "  Args:\n",
      "    genre: Sci-Fi\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: search_movies\n",
      "\n",
      "Dune, Interstellar, Blade Runner 2049\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The current weather in San Francisco is about 50.3°F with clear skies. As for some excellent Sci-Fi movies, you might enjoy watching Dune, Interstellar, or Blade Runner 2049.\n"
     ]
    }
   ],
   "source": [
    "from langchain.messages import HumanMessage\n",
    "\n",
    "question = \"What is the weather in SF today (37.77° N, 122.42° W), and what are some good Sci-Fi movies?\"\n",
    "\n",
    "result = agent.invoke({\"messages\": HumanMessage(content=question)})\n",
    "\n",
    "for message in result[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎉 Congratulations!\n",
    "\n",
    "You've learned the core concepts of building agents with LangChain and LangGraph:\n",
    "\n",
    " **Models** - Standardized interface across providers  \n",
    " **Messages** - Building block of conversations  \n",
    " **Tools** - Extending LLM capabilities  \n",
    " **Agents** - Automated reasoning and action loops  \n",
    " **Memory** - Maintaining context across interactions  \n",
    " **Streaming** - Real-time user experience  \n",
    " **LangGraph** - The foundation powering it all\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "1. **Build your own agent** with your specific tools and use case\n",
    "2. **Explore advanced patterns** in the `multi_agent.ipynb` notebook\n",
    "3. **Add debugging** with [LangSmith](https://smith.langchain.com)\n",
    "4. **Deploy to production** using LangGraph's persistence and error recovery\n",
    "\n",
    "### Resources:\n",
    "\n",
    "- [LangChain Documentation](https://python.langchain.com/docs/introduction/)\n",
    "- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)\n",
    "- [LangSmith for Debugging](https://smith.langchain.com)\n",
    "- [LangChain Academy](https://academy.langchain.com/)\n",
    "<br> \n",
    "<br> \n",
    "---\n",
    "<br> \n",
    "\n",
    "**Happy building!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
