{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangGraph Advanced Concepts: Middleware & Human-in-the-Loop\n",
    "\n",
    "Welcome to LangGraph Advanced Concepts! This notebook builds on the foundations from LangGraph 101 and introduces two powerful patterns for production agents.\n",
    "\n",
    "**What you'll learn:**\n",
    "- **Human-in-the-Loop** - Pause agents for human review and approval\n",
    "- **Middleware** - Modify agent behavior at key points in execution\n",
    "- **Tool Review** - Add approval workflows to sensitive tools\n",
    "- **Dynamic Behavior** - Adapt agent responses based on context\n",
    "\n",
    "**Prerequisites:** Complete `langgraph_101.ipynb` \n",
    "</br>\n",
    "</br>\n",
    "\n",
    "---\n",
    "</br>\n",
    "\n",
    "> **Note:** These patterns are essential for production agents where safety, compliance, and user control are critical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Let's quickly set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=\"../.env\", override=True)\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"openai:o3-mini\")\n",
    "# model = init_chat_model(\"anthropic:claude-haiku-4-5\")\n",
    "\n",
    "# Note: If you are using another `ChatModel`, you can define it in `models.py` and import it here\n",
    "# from models import AZURE_OPENAI_GPT_4O\n",
    "# model = AZURE_OPENAI_GPT_4O\n",
    "\n",
    "\n",
    "\n",
    "# Bedrock Version\n",
    "# from dotenv import load_dotenv\n",
    "# from langchain_aws import ChatBedrockConverse\n",
    "# import os\n",
    "\n",
    "# load_dotenv(dotenv_path=\"../.env\", override=True)\n",
    "\n",
    "# AWS_ACCESS_KEY_ID=os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "# AWS_SECRET_ACCESS_KEY=os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "# AWS_REGION_NAME=os.getenv(\"AWS_REGION_NAME\")\n",
    "# AWS_MODEL_ARN=os.getenv(\"AWS_MODEL_ARN\")\n",
    "\n",
    "# model = ChatBedrockConverse(\n",
    "#     aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "#     aws_secret_access_key=AWS_SECRET_ACCESS_KEY, \n",
    "#     region_name=AWS_REGION_NAME,\n",
    "#     provider=\"anthropic\",\n",
    "#     model_id=AWS_MODEL_ARN\n",
    "# )\n",
    "\n",
    "\n",
    "# Google Vertex AI version\n",
    "# Make sure you have your vertex ai credentials setup and your GOOGLE_APPLICATION_CREDENTIALS are pointing to the JSON file. \n",
    "\n",
    "# import os\n",
    "# from pathlib import Path\n",
    "# from dotenv import load_dotenv\n",
    "# from langchain.chat_models import init_chat_model\n",
    "\n",
    "# # Find project root and load .env\n",
    "# project_root = Path().resolve().parent.parent\n",
    "# load_dotenv(dotenv_path=project_root / \".env\", override=True)\n",
    "\n",
    "# # Fix credentials path to absolute\n",
    "# if \"GOOGLE_APPLICATION_CREDENTIALS\" in os.environ:\n",
    "#     cred_path = os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]\n",
    "#     if not os.path.isabs(cred_path):\n",
    "#         os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = str(project_root / cred_path.lstrip(\"./\"))\n",
    "\n",
    "# # Create model\n",
    "# model = init_chat_model(\"google_vertexai:gemini-2.5-flash\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Human-in-the-Loop with Interrupts\n",
    "\n",
    "### The Problem\n",
    "\n",
    "Imagine you're building an agent that can send emails or make purchases. You don't want it to take these actions automatically - you want human approval first!\n",
    "\n",
    "**Human-in-the-loop** lets you:\n",
    "- Pause execution for review\n",
    "- Approve, reject, or edit actions\n",
    "- Add safety controls to sensitive operations\n",
    "\n",
    "### How It Works\n",
    "\n",
    "1. Agent encounters an `interrupt()` - execution pauses\n",
    "2. System surfaces information to human\n",
    "3. Human provides input (approve/reject/edit)\n",
    "4. Agent resumes with `Command(resume=...)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Simple Approval Workflow\n",
    "\n",
    "Let's start with a simple example - asking for approval before sending an email."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import interrupt\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def send_email(to: str, subject: str, body: str) -> str:\n",
    "    \"\"\"Send an email to a recipient.\"\"\"\n",
    "    \n",
    "    # Pause for human approval\n",
    "    approval = interrupt({\n",
    "        \"action\": \"send_email\",\n",
    "        \"to\": to,\n",
    "        \"subject\": subject,\n",
    "        \"body\": body,\n",
    "        \"message\": \"Do you want to send this email?\"\n",
    "    })\n",
    "    \n",
    "    if approval.get(\"approved\"): # Will be true if accepted, false if declined\n",
    "        # In production, this would actually send the email\n",
    "        return f\" Email sent to {to} with subject '{subject}'\"\n",
    "    else:\n",
    "        return \"Email cancelled by user\"\n",
    "\n",
    "# Test the tool directly\n",
    "print(\"Tool created successfully!\")\n",
    "print(f\"Tool name: {send_email.name}\")\n",
    "print(f\"Tool description: {send_email.description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an Agent with Human-in-the-Loop\n",
    "\n",
    "Now let's create an agent that uses this tool. **Remember:** Interrupts require a checkpointer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# Create checkpointer for persistence\n",
    "checkpointer = MemorySaver()\n",
    "\n",
    "# Create agent with the email tool\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[send_email],\n",
    "    system_prompt=\"You are a helpful email assistant. When asked to send emails, use the send_email tool.\",\n",
    "    checkpointer=checkpointer  # Required for interrupts\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Until Interrupt\n",
    "\n",
    "Let's run the agent and see it pause for approval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import HumanMessage\n",
    "from langsmith import uuid7\n",
    "\n",
    "# Create a unique thread for this conversation\n",
    "config = {\"configurable\": {\"thread_id\": uuid7()}}\n",
    "\n",
    "# Run the agent and see it pause for approval\n",
    "result = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"Send an email to alice@example.com with subject 'Meeting Tomorrow' and body 'Let's meet at 3pm.'\")]\n",
    "    },\n",
    "    config=config\n",
    ")\n",
    "\n",
    "# Check if we hit an interrupt\n",
    "\n",
    "if \"__interrupt__\" in result:\n",
    "    print(\"Agent paused for approval\\n\")\n",
    "\n",
    "    interrupt_info = result[\"__interrupt__\"][0]\n",
    "\n",
    "    print(\"Interrupt details:\")\n",
    "    print(f\"  To: {interrupt_info.value['to']}\")\n",
    "    print(f\"  Subject: {interrupt_info.value['subject']}\")\n",
    "    print(f\"  Body: {interrupt_info.value['body']}\")\n",
    "    print(f\"  Message: {interrupt_info.value['message']}\")\n",
    "else:\n",
    "    print(\"Agent completed without interrupt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resuming with Approval\n",
    "\n",
    "Now let's approve the email and let the agent continue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import Command\n",
    "\n",
    "# Resume with approval\n",
    "result = agent.invoke(\n",
    "    Command(resume={\"approved\": True}),\n",
    "    config=config\n",
    ")\n",
    "\n",
    "# Print the final response\n",
    "print(\"Final response:\")\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Try Rejecting the Email\n",
    "\n",
    "Run the cells again, but this time reject the email by passing `{\"approved\": False}`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New thread for rejection example\n",
    "config_2 = {\"configurable\": {\"thread_id\": uuid7()}}\n",
    "\n",
    "# Run until interrupt\n",
    "result = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"Send an email to bob@example.com saying 'Hello!'\")]\n",
    "    },\n",
    "    config=config_2\n",
    ")\n",
    "\n",
    "# Resume with rejection\n",
    "result = agent.invoke(\n",
    "    Command(resume={\"approved\": False}),  # Reject the email\n",
    "    config=config_2\n",
    ")\n",
    "\n",
    "print(\"Final response:\")\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Advanced Pattern - Edit Before Execution\n",
    "\n",
    "Sometimes you want to **edit** the tool call, not just approve/reject it. Let's enhance our tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def send_email_v2(to: str, subject: str, body: str) -> str:\n",
    "    \"\"\"Send an email to a recipient.\"\"\"\n",
    "    \n",
    "    # Pause for human review\n",
    "    response = interrupt({\n",
    "        \"action\": \"send_email\",\n",
    "        \"to\": to,\n",
    "        \"subject\": subject,\n",
    "        \"body\": body,\n",
    "        \"message\": \"Review this email. You can approve, reject, or edit it.\"\n",
    "    })\n",
    "    \n",
    "    # Handle different response types\n",
    "    if response[\"type\"] == \"approve\":\n",
    "        return f\"Email sent to {to} with subject '{subject}'\"\n",
    "\n",
    "    elif response[\"type\"] == \"reject\":\n",
    "        return \"Email cancelled\"\n",
    "\n",
    "    elif response[\"type\"] == \"edit\":\n",
    "        # Use edited values\n",
    "        to = response.get(\"to\", to)\n",
    "        subject = response.get(\"subject\", subject)\n",
    "        body = response.get(\"body\", body)\n",
    "        return f\"\"\"Email sent with edits:\n",
    "                To: {to}\n",
    "                Subject: {subject}\n",
    "                Body: {body}\"\"\"\n",
    "    \n",
    "    return \"Unknown response\"\n",
    "\n",
    "# Create new agent with enhanced tool\n",
    "agent_v2 = create_agent(\n",
    "    model=model,\n",
    "    tools=[send_email_v2],\n",
    "    system_prompt=\"You are a helpful email assistant.\",\n",
    "    checkpointer=MemorySaver()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run and edit the email\n",
    "config_3 = {\"configurable\": {\"thread_id\": uuid7()}}\n",
    "\n",
    "# Run until interrupt\n",
    "result = agent_v2.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"Send an email to team@example.com about the meeting\")]\n",
    "    },\n",
    "    config=config_3\n",
    ")\n",
    "\n",
    "print(\"Paused for review...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets edit the email subject to make it URGENT meeting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume with edits\n",
    "result = agent_v2.invoke(\n",
    "    Command(resume={\n",
    "        \"type\": \"edit\",\n",
    "        \"subject\": \"URGENT: Meeting Today at 2pm\",  # We have edited the email subject\n",
    "        \"body\": \"This is the edited email body with more details.\"\n",
    "    }),\n",
    "    config=config_3\n",
    ")\n",
    "\n",
    "print(\"Final response:\")\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Introduction to Middleware\n",
    "\n",
    "**Middleware** provides fine-grained control over the agent loop. It lets you:\n",
    "- Inspect state before/after model calls\n",
    "- Modify model requests dynamically\n",
    "- Add custom logic at key execution points\n",
    "\n",
    "### The Agent Loop\n",
    "\n",
    "```\n",
    "Input --> [before_model] --> [wrap_model_call] --> Model --> [after_model] --> Tools --> ...\n",
    "```\n",
    "\n",
    "Middleware hooks into this loop:\n",
    "- **`before_model`** - Runs before model execution, can update state\n",
    "- **`wrap_model_call`** - Wraps the model call, control when/how the model is invoked\n",
    "- **`after_model`** - Runs after model execution, before tools\n",
    "\n",
    "### Two Hook Styles\n",
    "\n",
    "**Node-style hooks** run sequentially:\n",
    "- `before_agent`, `before_model`, `after_model`, `after_agent`\n",
    "- Good for logging, validation, state updates\n",
    "\n",
    "**Wrap-style hooks** intercept execution:\n",
    "- `wrap_model_call`, `wrap_tool_call`\n",
    "- Full control over handler calls\n",
    "- Good for retries, caching, transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Dynamic System Prompt\n",
    "\n",
    "Let's create middleware that changes the system prompt based on the user's role:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import dynamic_prompt, ModelRequest\n",
    "from typing import TypedDict\n",
    "\n",
    "# Define context schema\n",
    "class Context(TypedDict):\n",
    "    user_role: str\n",
    "\n",
    "# Create middleware using decorator\n",
    "@dynamic_prompt\n",
    "def dynamic_prompt_middleware(request: ModelRequest) -> str:\n",
    "    \"\"\"Adjust system prompt based on user role.\"\"\"\n",
    "    \n",
    "    user_role = request.runtime.context.get(\"user_role\", \"general\")\n",
    "    \n",
    "    if user_role == \"expert\":\n",
    "        return \"You are an AI assistant for experts. Provide detailed technical responses with code examples.\"\n",
    "    elif user_role == \"beginner\":\n",
    "        return \"You are an AI assistant for beginners. Explain concepts simply, avoid jargon.\"\n",
    "    else:\n",
    "        return \"You are a helpful AI assistant.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def explain_concept(concept: str) -> str:\n",
    "    \"\"\"Explain a programming concept.\"\"\"\n",
    "    explanations = {\n",
    "        \"async\": \"Asynchronous programming allows code to run without blocking.\",\n",
    "        \"recursion\": \"Recursion is when a function calls itself.\"\n",
    "    }\n",
    "    return explanations.get(concept.lower(), \"Concept not found.\")\n",
    "\n",
    "# Create agent with middleware\n",
    "agent_with_middleware = create_agent(\n",
    "    model=model,\n",
    "    tools=[explain_concept],\n",
    "    middleware=[dynamic_prompt_middleware],\n",
    "    context_schema=Context\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Different User Roles\n",
    "\n",
    "Let's see how the agent responds differently based on user role:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expert user\n",
    "print(\"=\" * 50)\n",
    "print(\"EXPERT USER\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "result = agent_with_middleware.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"Explain async programming\")]},\n",
    "    context={\"user_role\": \"expert\"}\n",
    ")\n",
    "print(result[\"messages\"][-1].content)\n",
    "print()\n",
    "\n",
    "# Beginner user\n",
    "print(\"=\" * 50)\n",
    "print(\"BEGINNER USER\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "result = agent_with_middleware.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"Explain async programming\")]},\n",
    "    context={\"user_role\": \"beginner\"}\n",
    ")\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Custom Middleware - Request Logger\n",
    "\n",
    "Middleware lets you hook into the agent loop and see what's happening at each step. This is incredibly useful for debugging and understanding how your agent works.\n",
    "\n",
    "**The Agent Loop:**\n",
    "User Input --> [before_model] --> [wrap_model_call] --> Model --> [after_model] --> Tools --> ...\n",
    "\n",
    "**What we'll build:**\n",
    "A logger that prints information at each step:\n",
    "- **Before model** - How many messages are in the conversation?\n",
    "- **Wrap model call** - Which model and tools are being used?\n",
    "- **After model** - Did the model call a tool or give a final answer?\n",
    "\n",
    "This is like adding debug `print()` statements, but in a clean, reusable way!\n",
    "\n",
    "Let's create middleware that logs model requests for debugging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import AgentMiddleware, AgentState, ModelRequest, ModelResponse\n",
    "from typing import Any, Callable\n",
    "\n",
    "class RequestLoggerMiddleware(AgentMiddleware):\n",
    "    \"\"\"Logs all model requests for debugging.\"\"\"\n",
    "    \n",
    "    def before_model(self, state: AgentState, runtime) -> dict[str, Any] | None:\n",
    "        \"\"\"Log before model execution.\"\"\"\n",
    "        message_count = len(state.get(\"messages\", []))\n",
    "        print(f\"[BEFORE MODEL] Processing {message_count} messages\")\n",
    "        return None  # Don't modify state\n",
    "    \n",
    "    def wrap_model_call(\n",
    "        self, \n",
    "        request: ModelRequest,\n",
    "        handler: Callable[[ModelRequest], ModelResponse]\n",
    "    ) -> ModelResponse:\n",
    "        \"\"\"Log the model request details and call the handler.\"\"\"\n",
    "        print(f\"  [MODEL REQUEST]\")\n",
    "        print(f\"   Model: {request.model if hasattr(request, 'model') else 'default'}\")\n",
    "        print(f\"   Tools available: {len(request.tools) if request.tools else 0}\")\n",
    "        \n",
    "        # Call the actual model handler\n",
    "        return handler(request)\n",
    "    \n",
    "    def after_model(self, state: AgentState, runtime) -> dict[str, Any] | None:\n",
    "        \"\"\"Log after model execution.\"\"\"\n",
    "        last_message = state[\"messages\"][-1]\n",
    "        if hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
    "            print(f\" [AFTER MODEL] Model requested {len(last_message.tool_calls)} tool call(s)\")\n",
    "        else:\n",
    "            print(f\" [AFTER MODEL] Model provided final response\")\n",
    "        return None  # Don't modify state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create agent with logger middleware\n",
    "agent_with_logger = create_agent(\n",
    "    model=model,\n",
    "    tools=[explain_concept],\n",
    "    middleware=[RequestLoggerMiddleware()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What to Expect\n",
    "\n",
    "When we run the agent with the logger, you'll see the execution flow in real-time:\n",
    "\n",
    "**First iteration:**\n",
    "1. `[BEFORE MODEL]` - Shows how many messages we're starting with\n",
    "2. `[MODEL REQUEST]` - Shows which model and tools are available (from wrap_model_call)\n",
    "3. `[AFTER MODEL]` - The model decides to call the `explain_concept` tool\n",
    "\n",
    "**Second iteration (after tool execution):**\n",
    "1. `[BEFORE MODEL]` - Now we have more messages (including tool result)\n",
    "2. `[MODEL REQUEST]` - Model info again\n",
    "3. `[AFTER MODEL]` - Model provides the final answer (no more tools needed)\n",
    "\n",
    "This gives you a detailed view into your agent's decision-making process.\n",
    "\n",
    "Let's run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run and observe the logs\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"RUNNING AGENT WITH LOGGER\")\n",
    "print(\"=\" * 50 + \"\\n\")\n",
    "\n",
    "result = agent_with_logger.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Explain recursion\"}]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"FINAL RESPONSE\")\n",
    "print(\"=\" * 50)\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Combining Middleware and Human-in-the-loop\n",
    "\n",
    "Let's combine human-in-the-loop AND middleware for a production-ready agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensitive tool that needs approval\n",
    "@tool\n",
    "def delete_database(database_name: str) -> str:\n",
    "    \"\"\"Delete a database. THIS IS DANGEROUS!\"\"\"\n",
    "    \n",
    "    response = interrupt({\n",
    "        \"action\": \"delete_database\",\n",
    "        \"database_name\": database_name,\n",
    "        \"warning\": \"This will permanently delete the database!\",\n",
    "        \"message\": \"Are you absolutely sure?\"\n",
    "    })\n",
    "    \n",
    "    if response.get(\"confirmed\"):\n",
    "        return f\"Database '{database_name}' has been deleted (simulation)\"\n",
    "    else:\n",
    "        return \"Database deletion cancelled\"\n",
    "\n",
    "# Middleware to track dangerous operations\n",
    "class SafetyMiddleware(AgentMiddleware):\n",
    "    \"\"\"Add safety checks and logging.\"\"\"\n",
    "    \n",
    "    name = \"safety_checker\"\n",
    "    \n",
    "    def after_model(self, state: AgentState) -> dict[str, Any] | None:\n",
    "        \"\"\"Check for dangerous tool calls.\"\"\"\n",
    "        last_message = state[\"messages\"][-1]\n",
    "        \n",
    "        if hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
    "            for tool_call in last_message.tool_calls:\n",
    "                if \"delete\" in tool_call[\"name\"].lower():\n",
    "                    print(\"   [SAFETY] Dangerous operation detected!\")\n",
    "                    print(f\"   Tool: {tool_call['name']}\")\n",
    "                    print(f\"   Args: {tool_call['args']}\")\n",
    "        \n",
    "        return None\n",
    "\n",
    "# Create production agent\n",
    "production_agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[delete_database],\n",
    "    middleware=[SafetyMiddleware()],\n",
    "    checkpointer=MemorySaver()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### What to Expect: Layered Safety in Action\n",
    "\n",
    "  When we attempt a dangerous operation, you'll see **both** safety mechanisms activate:\n",
    "\n",
    "  **Layer 1 - Middleware Detection:**\n",
    "  - `[SAFETY] Dangerous operation detected!` - Middleware spots the delete operation\n",
    "  - Logs the tool name and arguments for audit trails\n",
    "\n",
    "  **Layer 2 - Human Approval (Interrupt):**\n",
    "  - Agent execution pauses at the `interrupt()`\n",
    "  - Warning message displayed to human reviewer\n",
    "  - Execution won't continue until explicit approval\n",
    "\n",
    "  **This is defense-in-depth:** Middleware monitors ALL operations, while interrupts enforce human approval for critical actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the combined pattern\n",
    "config_4 = {\"configurable\": {\"thread_id\": uuid7()}}\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"DANGEROUS OPERATION ATTEMPT\")\n",
    "print(\"=\" * 50 + \"\\n\")\n",
    "\n",
    "# Run until interrupt\n",
    "result = production_agent.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"Delete the production_db database\")]\n",
    "    },\n",
    "    config=config_4\n",
    ")\n",
    "\n",
    "if \"__interrupt__\" in result:\n",
    "    interrupt_info = result[\"__interrupt__\"][0]\n",
    "    print(\"\\n  Human approval required:\")\n",
    "    print(f\"   {interrupt_info.value['warning']}\")\n",
    "    print(f\"   Database: {interrupt_info.value['database_name']}\")\n",
    "\n",
    "print(\"\\n(In a real app, a human would review this before proceeding)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### Human-in-the-Loop (Interrupts)\n",
    "- Use `interrupt()` to pause execution\n",
    "- Requires a `checkpointer` for persistence\n",
    "- Resume with `Command(resume=value)`\n",
    "- Perfect for approval workflows and sensitive operations\n",
    "\n",
    "### Middleware\n",
    "- **Node-style hooks**: `before_model`, `after_model` - Sequential logic, validation, logging\n",
    "- **Wrap-style hooks**: `wrap_model_call`, `wrap_tool_call` - Full control, retries, transformation\n",
    "- **Decorators**: `@dynamic_prompt`, `@before_model`, `@wrap_model_call` for quick middleware\n",
    "- **Classes**: Subclass `AgentMiddleware` for complex, reusable components\n",
    "\n",
    "### When to Use What?\n",
    "\n",
    "**Use Interrupts when:**\n",
    "- You need human approval for actions\n",
    "- You want to review/edit tool calls\n",
    "- You need to validate user input\n",
    "\n",
    "**Use Middleware when:**\n",
    "- You need to modify agent behavior dynamically\n",
    "- You want to add logging/monitoring\n",
    "- You need to enforce policies (token limits, safety checks)\n",
    "- You want to personalize responses based on context\n",
    "\n",
    "**Node-style vs Wrap-style:**\n",
    "- Node-style for sequential operations (logging, validation)\n",
    "- Wrap-style for control flow (retry, fallback, caching)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Exercise (Optional)\n",
    "\n",
    "Try building an agent that:\n",
    "1. Has a tool to make a purchase\n",
    "2. Uses middleware to check if the purchase amount is over $1000\n",
    "3. If over $1000, uses an interrupt to require approval\n",
    "4. If under $1000, processes automatically\n",
    "\n",
    "Hint: Combine `before_model` middleware with conditional `interrupt()` logic!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here!\n",
    "# Challenge: Build the purchase approval agent\n",
    "\n",
    "# @tool\n",
    "# def make_purchase(item: str, amount: float) -> str:\n",
    "#     ...\n",
    "\n",
    "# class PurchaseLimitMiddleware(AgentMiddleware):\n",
    "#     ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "You now have powerful tools for building production agents!\n",
    "\n",
    "**Continue your journey:**\n",
    "1.  Check out `multi_agent.ipynb` for multi-agent systems\n",
    "2.  Explore built-in middleware (Summarization, Anthropic Prompt Caching)\n",
    "3.  Build your own custom middleware for your use case\n",
    "4.  Add LangSmith for debugging and monitoring\n",
    "\n",
    "**Resources:**\n",
    "- [Middleware Documentation](https://docs.langchain.com/oss/python/langchain/middleware)\n",
    "- [Human-in-the-Loop Guide](https://docs.langchain.com/oss/python/langchain/human-in-the-loop)\n",
    "- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)\n",
    "\n",
    "</br>\n",
    "</br>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
