from langchain.chat_models import init_chat_model
import sqlite3
import requests
from sqlalchemy import create_engine
from sqlalchemy.pool import StaticPool

# NOTE: Configure the LLM that you want to use
llm = init_chat_model("openai:gpt-4o")

def get_engine_for_chinook_db():
    """Pull sql file, populate in-memory database, and create engine."""
    url = "https://raw.githubusercontent.com/lerocha/chinook-database/master/ChinookDatabase/DataSources/Chinook_Sqlite.sql"
    response = requests.get(url)
    sql_script = response.text

    connection = sqlite3.connect(":memory:", check_same_thread=False)
    connection.executescript(sql_script)
    return create_engine(
        "sqlite://",
        creator=lambda: connection,
        poolclass=StaticPool,
        connect_args={"check_same_thread": False},
    )